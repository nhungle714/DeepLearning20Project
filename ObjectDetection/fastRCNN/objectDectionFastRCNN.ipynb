{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"objectDectionFastRCNN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d976eaba52b14826a08be77806716d55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e8b3bddac3a340148ff50ba131e07f72","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_81d865a923a24650be500c823da350e6","IPY_MODEL_8e8204efdde4444c9bd6b9fd195a5287"]}},"e8b3bddac3a340148ff50ba131e07f72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81d865a923a24650be500c823da350e6":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_df4c4eca7ab8427fb66a258f9b69d670","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":167502836,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":167502836,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee12afe586f74133aee8e354af1e239c"}},"8e8204efdde4444c9bd6b9fd195a5287":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_03f72777ea534c218cb8be8e6a8cb477","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 160M/160M [01:16&lt;00:00, 2.19MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3043631df8a48ca93dca05b923be2f6"}},"df4c4eca7ab8427fb66a258f9b69d670":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ee12afe586f74133aee8e354af1e239c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03f72777ea534c218cb8be8e6a8cb477":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e3043631df8a48ca93dca05b923be2f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LMpEF8ZDd-lt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"3a10511e-b657-42f4-a288-7459399306c2","executionInfo":{"status":"ok","timestamp":1587653021395,"user_tz":240,"elapsed":23589,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6qAWv9YOfRAi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":155},"outputId":"f722d12e-67fe-43ab-e0af-6dadd9d2a3c5","executionInfo":{"status":"ok","timestamp":1587653056609,"user_tz":240,"elapsed":2608,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["import os\n","!ls \n","os.chdir('gdrive/My Drive/dl20/final_project/FinalProject')\n","\n","!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["gdrive\tsample_data\n","'=1.4'\t\t  env\t\t\t     objectDectionFastRCNN.ipynb\n","'=2.0.8'\t  explore_the_data.ipynb     __pycache__\n"," coco_eval.py\t  group_by_aspect_ratio.py   README.md\n"," coco_utils.py\t  helper.py\t\t     requirements.txt\n"," data\t\t  Mask_RCNN\t\t     train.py\n"," data_helper.py   MaskRCNN.ipynb\t     transforms.py\n"," engine.py\t  model_loader.py\t     utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X9PMrKKreF3N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"95c4a200-1b03-4b39-cb97-de77816f6c44","executionInfo":{"status":"ok","timestamp":1587653062423,"user_tz":240,"elapsed":4310,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["import os\n","from PIL import Image\n","\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","matplotlib.rcParams['figure.figsize'] = [5, 5]\n","matplotlib.rcParams['figure.dpi'] = 200\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","from data_helper import *\n","from helper import collate_fn, draw_box\n","\n","import pickle\n","import time\n","import copy"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"23wjtm3ufX2t","colab_type":"text"},"source":["# Test an example code"]},{"cell_type":"code","metadata":{"id":"Z-mow3YMfT-_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["d976eaba52b14826a08be77806716d55","e8b3bddac3a340148ff50ba131e07f72","81d865a923a24650be500c823da350e6","8e8204efdde4444c9bd6b9fd195a5287","df4c4eca7ab8427fb66a258f9b69d670","ee12afe586f74133aee8e354af1e239c","03f72777ea534c218cb8be8e6a8cb477","e3043631df8a48ca93dca05b923be2f6"]},"outputId":"86d3d876-7f7e-4968-8d21-a82f2d6da56f","executionInfo":{"status":"ok","timestamp":1587653086288,"user_tz":240,"elapsed":25411,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)\n","labels = torch.randint(1, 91, (4, 11))\n","images = list(image for image in images)\n","targets = []\n","for i in range(len(images)):\n","    d = {}\n","    d['boxes'] = boxes[i]\n","    d['labels'] = labels[i]\n","    targets.append(d)\n","output = model(images, targets)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d976eaba52b14826a08be77806716d55","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=167502836), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iQ7-Fn_eg_f_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"f4d7b6c4-2b71-44af-ad75-e55d1ed9d64d","executionInfo":{"status":"ok","timestamp":1587653086289,"user_tz":240,"elapsed":19505,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["output"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'loss_box_reg': tensor(0.0049, grad_fn=<DivBackward0>),\n"," 'loss_classifier': tensor(0.1286, grad_fn=<NllLossBackward>),\n"," 'loss_objectness': tensor(13.9017, grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n"," 'loss_rpn_box_reg': tensor(nan, grad_fn=<DivBackward0>)}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"A16_Anied-mJ","colab_type":"code","colab":{}},"source":["# All the images are saved in image_folder\n","# All the labels are saved in the annotation_csv file\n","\n","# image_folder = '../data'\n","# annotation_csv = '../data/annotation.csv'\n","\n","image_folder = 'data'\n","annotation_csv = 'data/annotation.csv'\n","labeled_scene_index = np.arange(133, 134)\n","\n","# image_folder = '/Users/nhungle/Downloads/dl20_data'\n","# annotation_csv = '/Users/nhungle/Downloads/dl20_data/annotation.csv'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tVqN7YCd-nQ","colab_type":"code","colab":{}},"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if cuda else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n-PzB4lPd-n7","colab_type":"text"},"source":["# Labeled dataset"]},{"cell_type":"code","metadata":{"id":"Mk75N39Cd-n8","colab_type":"code","colab":{}},"source":["def inspect_target(index):\n","    NUM_SAMPLE_PER_SCENE = 126\n","    NUM_IMAGE_PER_SAMPLE = 6\n","    image_names = [\n","        'CAM_FRONT_LEFT.jpeg',\n","        'CAM_FRONT.jpeg',\n","        'CAM_FRONT_RIGHT.jpeg',\n","        'CAM_BACK_LEFT.jpeg',\n","        'CAM_BACK.jpeg',\n","        'CAM_BACK_RIGHT.jpeg',\n","        ]\n","    scene_index = labeled_scene_index \n","    scene_id = scene_index[index // NUM_SAMPLE_PER_SCENE]\n","    sample_id = index % NUM_SAMPLE_PER_SCENE\n","    sample_path = os.path.join(image_folder, f'scene_{scene_id}', f'sample_{sample_id}') \n","    images = []\n","    for image_name in image_names:\n","        image_path = os.path.join(sample_path, image_name)\n","        image = Image.open(image_path)\n","        images.append(transform(image))\n","    image_tensor = torch.stack(images)\n","    annotation_file = annotation_csv \n","    annotation_dataframe = pd.read_csv(annotation_file)\n","    data_entries = annotation_dataframe[(annotation_dataframe['scene'] == scene_id) & (annotation_dataframe['sample'] == sample_id)]\n","    corners = data_entries[['fl_x', 'fr_x', 'bl_x', 'br_x', 'fl_y', 'fr_y','bl_y', 'br_y']].to_numpy()\n","    categories = data_entries.category_id.to_numpy()\n","    num_objects = len(categories)\n","    boxes = []\n","    for i in range(num_objects):\n","        xmin = min(corners[i][:4])\n","        xmax = max(corners[i][:4])\n","        ymin = min(corners[i][4:])\n","        ymax = max(corners[i][4:])\n","        boxes.append([xmin, ymin, xmax, ymax])\n","    return data_entries, image_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fom2g6MJd-oP","colab_type":"code","colab":{}},"source":["# The labeled dataset can only be retrieved by sample.\n","# And all the returned data are tuple of tensors, since bounding boxes may have different size\n","# You can choose whether the loader returns the extra_info. It is optional. You don't have to use it.\n","transform = torchvision.transforms.ToTensor()\n","labeled_trainset = LabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","fasterRCNN_trainset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","train_loader = torch.utils.data.DataLoader(fasterRCNN_trainset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HFKc2hcbN3e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0af1b5b0-05ea-4822-a615-2e56c73c9a54","executionInfo":{"status":"ok","timestamp":1587649500820,"user_tz":240,"elapsed":726,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["train_loader.__len__()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["126"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"-I7CPU6Gd-oi","colab_type":"code","colab":{}},"source":["sample, targets = iter(train_loader).next()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iQADn5EVgAKg","colab_type":"code","colab":{}},"source":["#targets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pgjt4k2VRU0n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"88a456da-f74c-4b6c-ed08-41f76671bf51","executionInfo":{"status":"ok","timestamp":1587653114243,"user_tz":240,"elapsed":7329,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["sample[0].shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([6, 3, 256, 306])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"XxJdONjld-oy","colab_type":"code","outputId":"f6367e4c-3d70-4a86-a9cb-cd92b32e20e8","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1587653114431,"user_tz":240,"elapsed":6806,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["index = targets[0]['image_id'].item()\n","data_entries, idx_tensor = inspect_target(index)\n","data_entries[\"category_id\"].values == targets[0]['labels'].data.numpy()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True,  True,  True,  True])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"pq87_1TsZdxH","colab_type":"text"},"source":["## Prepare inputs for the model"]},{"cell_type":"code","metadata":{"id":"C3v00HG3ZdJP","colab_type":"code","colab":{}},"source":["def extract_features(one_sample):\n","    feature_extractor = torchvision.models.resnet18(pretrained=False)\n","    feature_extractor = nn.Sequential(*list(feature_extractor.children())[:-2])\n","    #feature_extractor.to(device)\n","    # for param in feature_extractor.parameters():\n","    #     param.requires_grad = True\n","    return feature_extractor(one_sample)\n","\n","\n","def concat_features(features, dim = 2):\n","    #dim 0 ==> stacking the images in the channel dimension\n","    #dim 1 ==> stacking the images in row dimension\n","    #dim 2 ==> stacking the images in column dimension\n","    tensor_tuples = torch.unbind(features, dim=0)\n","    concatenated_fm = torch.cat(tensor_tuples, dim=dim)\n","    return concatenated_fm \n","\n","def prepare_inputs(sample):\n","    \"\"\"\n","    Input: samples is a cuda tensor with size [batch_size, 6, 3, 256, 306]\n","    Output: a list of batch_size tensor, each tensor with size [512, 16, 114]\n","    \"\"\"\n","    batchsize = sample.shape[0]\n","    fe_batch = []\n","    for i in range(batchsize):\n","        image_tensor = sample[i]\n","        features = extract_features(image_tensor)\n","        #print(features.shape)\n","        features = concat_features(features)\n","        features = features.view(3, 512, 160)\n","        #print(features.shape)\n","        fe_batch.append(features)\n","    \n","    return fe_batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuAHlunjZlLB","colab_type":"code","colab":{}},"source":["sample = torch.stack(sample)\n","images = prepare_inputs(sample)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_RhualMZrmB","colab_type":"code","colab":{}},"source":["images = list(image.to(device) for image in images)\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrbXoiO4RGse","colab_type":"text"},"source":["## Test pretrained model on my input"]},{"cell_type":"code","metadata":{"id":"LRNs29FNRGB_","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r551MU-nd-qk","colab_type":"code","colab":{}},"source":["output1 = model(images, targets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0Hxh3tYazHV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"aca552aa-3a2d-4202-9e0e-9cb7a61fd0c9","executionInfo":{"status":"ok","timestamp":1587653233103,"user_tz":240,"elapsed":922,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["output1"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'loss_box_reg': tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>),\n"," 'loss_classifier': tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward>),\n"," 'loss_objectness': tensor(1.8566, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n"," 'loss_rpn_box_reg': tensor(0.6337, device='cuda:0', grad_fn=<DivBackward0>)}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"eY5lf6lfbZTU","colab_type":"text"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"k2p5G8s6cRBv","colab_type":"code","colab":{}},"source":["# Refer to: https://github.com/pytorch/vision/blob/master/references/detection/engine.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RCAioWzd_RC","colab_type":"code","colab":{}},"source":["train_labeled_scene_index = np.arange(133, 134)\n","test_labeled_scene_index = np.arange(132, 133)\n","fasterRCNN_trainset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=train_labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","train_loader = torch.utils.data.DataLoader(fasterRCNN_trainset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)\n","fasterRCNN_testset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=test_labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","test_loader = torch.utils.data.DataLoader(fasterRCNN_testset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEsCSbEEdsgC","colab_type":"code","colab":{}},"source":["import math\n","import sys\n","import time\n","import torch\n","\n","from coco_utils import get_coco_api_from_dataset\n","from coco_eval import CocoEvaluator\n","import utils\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0mfqyfzbYgy","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                            momentum=0.9, weight_decay=0.0005)\n","# and a learning rate scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                step_size=3,\n","                                                gamma=0.1)\n","\n","# let's train it for 10 epochs\n","num_epochs = 1\n","epoch = 0\n","print_freq = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7REJR4wZiZEv","colab_type":"code","colab":{}},"source":["def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n","    model.train()\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n","    header = 'Epoch: [{}]'.format(epoch)\n","\n","    lr_scheduler = None\n","    if epoch == 0:\n","        warmup_factor = 1. / 1000\n","        warmup_iters = min(1000, len(data_loader) - 1)\n","\n","        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n","\n","    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n","        images = torch.stack(images)\n","        #print(images.shape)\n","        images = prepare_inputs(images)\n","        #print(images[0].shape)\n","\n","        images = list(image.to(device) for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        #print(loss_dict)\n","\n","        losses = sum(loss for loss in loss_dict.values())\n","        #print(losses)\n","\n","        # reduce losses over all GPUs for logging purposes\n","        loss_dict_reduced = utils.reduce_dict(loss_dict)\n","        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n","\n","        loss_value = losses_reduced.item()\n","\n","        if not math.isfinite(loss_value):\n","            print(\"Loss is {}, stopping training\".format(loss_value))\n","            print(loss_dict_reduced)\n","            sys.exit(1)\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","\n","        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n","\n","    return losses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNgNdjDyimY4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"outputId":"444dc2bc-7f90-4c75-ff54-bb9e20a1d853","executionInfo":{"status":"ok","timestamp":1587653732284,"user_tz":240,"elapsed":256261,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch: [0]  [  0/126]  eta: 0:16:09  lr: 0.000045  loss: 3.5067 (3.5067)  loss_classifier: 0.1825 (0.1825)  loss_box_reg: 0.0031 (0.0031)  loss_objectness: 2.2249 (2.2249)  loss_rpn_box_reg: 1.0963 (1.0963)  time: 7.6930  data: 5.4780  max mem: 2438\n","Epoch: [0]  [ 20/126]  eta: 0:04:11  lr: 0.000844  loss: 1.5302 (1.7125)  loss_classifier: 0.1288 (0.1735)  loss_box_reg: 0.0069 (0.0110)  loss_objectness: 0.4034 (0.7001)  loss_rpn_box_reg: 0.7716 (0.8280)  time: 2.1085  data: 0.1802  max mem: 2704\n","Epoch: [0]  [ 40/126]  eta: 0:03:05  lr: 0.001643  loss: 1.0577 (1.4125)  loss_classifier: 0.1129 (0.1459)  loss_box_reg: 0.0035 (0.0089)  loss_objectness: 0.2668 (0.5234)  loss_rpn_box_reg: 0.6072 (0.7344)  time: 1.9317  data: 0.0042  max mem: 2704\n","Epoch: [0]  [ 60/126]  eta: 0:02:17  lr: 0.002443  loss: 0.8366 (1.2275)  loss_classifier: 0.1055 (0.1352)  loss_box_reg: 0.0092 (0.0105)  loss_objectness: 0.1393 (0.3985)  loss_rpn_box_reg: 0.5202 (0.6833)  time: 1.9213  data: 0.0039  max mem: 2704\n","Epoch: [0]  [ 80/126]  eta: 0:01:33  lr: 0.003242  loss: 0.6872 (1.0948)  loss_classifier: 0.1193 (0.1306)  loss_box_reg: 0.0187 (0.0121)  loss_objectness: 0.1061 (0.3268)  loss_rpn_box_reg: 0.4411 (0.6254)  time: 1.9169  data: 0.0038  max mem: 2704\n","Epoch: [0]  [100/126]  eta: 0:00:53  lr: 0.004041  loss: 0.6774 (1.0119)  loss_classifier: 0.1079 (0.1295)  loss_box_reg: 0.0189 (0.0136)  loss_objectness: 0.0657 (0.2765)  loss_rpn_box_reg: 0.4466 (0.5922)  time: 2.0496  data: 0.1210  max mem: 2704\n","Epoch: [0]  [120/126]  eta: 0:00:12  lr: 0.004840  loss: 0.5424 (0.9389)  loss_classifier: 0.1315 (0.1316)  loss_box_reg: 0.0284 (0.0166)  loss_objectness: 0.0330 (0.2378)  loss_rpn_box_reg: 0.3169 (0.5528)  time: 1.9985  data: 0.0774  max mem: 2704\n","Epoch: [0]  [125/126]  eta: 0:00:02  lr: 0.005000  loss: 0.5264 (0.9286)  loss_classifier: 0.1315 (0.1322)  loss_box_reg: 0.0363 (0.0171)  loss_objectness: 0.0413 (0.2311)  loss_rpn_box_reg: 0.3169 (0.5481)  time: 1.9931  data: 0.0775  max mem: 2704\n","Epoch: [0] Total time: 0:04:15 (2.0307 s / it)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<utils.MetricLogger at 0x7f0ac0341e48>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"bKLzAqS5jayO","colab_type":"text"},"source":["## Evaluate"]},{"cell_type":"code","metadata":{"id":"6N7S-1srTbRg","colab_type":"code","colab":{}},"source":["def prepare_pred_results(predictions):\n","    pred_boxes = []\n","    pred_labels = []\n","    pred_scores = []\n","    for prediction in predictions:\n","        #print(prediction)\n","        if len(prediction) == 0:\n","            continue\n","        boxes = prediction[\"boxes\"]\n","        boxes = reorder_coord(boxes).tolist()\n","        scores = prediction[\"scores\"].tolist()\n","        labels = prediction[\"labels\"].tolist()\n","\n","        pred_boxes.append(boxes)\n","        pred_labels.append(labels)\n","        pred_scores.append(scores)\n","\n","    return pred_boxes, pred_labels, pred_scores\n","\n","def reorder_coord(boxes):\n","    xmin, ymin, xmax, ymax = boxes.unbind(1)\n","    return torch.stack((ymin, xmin, ymax, xmax), dim=1)\n","\n","def prepare_gt(targets):\n","    gt_boxes = []\n","    gt_labels = []\n","    for target in targets:\n","        boxes = target['boxes']\n","        boxes = reorder_coord(boxes).tolist()\n","        labels = target[\"labels\"].tolist()\n","        gt_boxes.append(boxes)\n","        gt_labels.append(labels)\n","    return gt_boxes, gt_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2a_EldORlxqm","colab_type":"code","colab":{}},"source":["# Make sure that bbox_a, bbox_b = np.array\n","\n","def bbox_iou(bbox_a, bbox_b):\n","    #print(type(bbox_a), type(bbox_b))\n","    if type(bbox_a) == list or type(bbox_b) == list:\n","        bbox_a = np.array(bbox_a)\n","        bbox_b = np.array(bbox_b)\n","    #print(type(bbox_a), type(bbox_b))\n","    if bbox_a.shape[1] != 4 or bbox_b.shape[1] != 4:\n","        raise IndexError\n","\n","    # top left (i.e., ymin, xmin)\n","    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n","    # bottom right (i.e., ymax, xmax)\n","    br = np.minimum(bbox_a[:, None, 2:], bbox_b[:, 2:])\n","\n","    # Area of intersection: (tl < br) = bool, (br-tl) = (ymax-ymin) \n","    area_i = np.prod(br - tl, axis=2) * (tl < br).all(axis=2)\n","    area_a = np.prod(bbox_a[:, 2:] - bbox_a[:, :2], axis=1)\n","    area_b = np.prod(bbox_b[:, 2:] - bbox_b[:, :2], axis=1)\n","\n","    return area_i / (area_a[:, None] + area_b - area_i)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahoOrX-8ZFzT","colab_type":"code","colab":{}},"source":["def cal_TP_FP_iou(pred_bbox_c, gt_bbox_c, iou_thres=0.5):\n","    iou_table = bbox_iou(pred_bbox_c, gt_bbox_c)\n","    num_pred_bboxes = iou_table.shape[0]\n","    num_gt_bboxes = iou_table.shape[1]\n","    TP = np.zeros(num_pred_bboxes)\n","    FP = np.zeros(num_pred_bboxes)\n","    # For each pred_bounding box:\n","      # Find the most relevant gt_bbox (i.e., the gt_bbox with max IoU)\n","      # If IoU < threshold, then flag it as FP\n","      # If IoU >= threshold, then:\n","        # If that gt_bbox already has already matched with another pred_bbox:\n","          # Flag it as FP\n","        # Else:\n","          # Flag it as TP\n","\n","    # TP only happens if the pred_bbox mathes with a gt_bbox\n","    for i in range(num_pred_bboxes):\n","        gt_bbox_index = np.argmax(iou_table[i])\n","        best_pred_bbox_index_for_selected_gt_bbox = np.argmax(iou_table[:,gt_bbox_index])\n","        if iou_table[i, gt_bbox_index] > iou_thres \\\n","            and gt_bbox_index == best_pred_bbox_index_for_selected_gt_bbox:\n","            TP[i] = 1\n","        else:\n","            FP[i] = 1\n","\n","    TP_cum = np.sum(TP)\n","    FP_cum = np.sum(FP)\n","\n","    if (TP_cum + FP_cum) != num_pred_bboxes:\n","        print(\"WRONG CALCULATION OF FP\")\n","    return TP_cum, FP_cum"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bzx15kDKS3Zt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"924e3ad3-ee58-4a6e-8550-2602c473e0e4","executionInfo":{"status":"ok","timestamp":1587684042603,"user_tz":240,"elapsed":1866,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["# Test for cal_TP_FP_iou\n","\n","test_images, test_targets = next(iter(test_loader))\n","test_images = torch.stack(test_images)\n","#print(test_images.shape)\n","test_images = prepare_inputs(test_images)\n","#print(test_images[0].shape)\n","\n","test_images = list(image.to(device) for image in test_images)\n","test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","model.eval()\n","predictions = model(test_images)\n","\n","pred_bboxes, pred_labels, pred_scores = prepare_pred_results(predictions)\n","gt_bboxes, gt_labels = prepare_gt(test_targets)\n","\n","for pred_bbox, pred_label, pred_score, gt_bbox, gt_label in \\\n","    zip(pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels):\n","    pred_bbox = np.array(pred_bbox)\n","    pred_score = np.array(pred_score)\n","    pred_label = np.array(pred_label)\n","    gt_bbox = np.array(gt_bbox)\n","    gt_label = np.array(gt_label)\n","    unique_share_classes = (np.unique(np.concatenate((pred_label, gt_label))))\n","    \n","    for c in unique_share_classes:\n","        pred_class_c_index = np.where(pred_label == c)[0]\n","        pred_bbox_c = pred_bbox[pred_class_c_index]\n","        gt_class_c_index = np.where(gt_label == c)[0]\n","        #print(gt_class_c_index)\n","        gt_bbox_c = gt_bbox[gt_class_c_index]\n","        num_gt_bboxes = len(gt_class_c_index)\n","        num_pred_bboxes = len(pred_class_c_index)\n","        print(num_gt_bboxes)\n","        print(num_pred_bboxes)\n","        TP, FP = cal_TP_FP_iou(pred_bbox_c, gt_bbox_c)\n","        print(TP + FP == num_pred_bboxes)"],"execution_count":411,"outputs":[{"output_type":"stream","text":["1\n","0\n","True\n","17\n","100\n","True\n","7\n","0\n","True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"honU3_7QQLwr","colab_type":"code","colab":{}},"source":["def evaluate_one_batch(predictions, test_targets, iou_thres=0.5, res=res):\n","\n","    pred_bboxes, pred_labels, pred_scores = prepare_pred_results(predictions)\n","    gt_bboxes, gt_labels = prepare_gt(test_targets)\n","    # res stores the TP_FP dict for each class\n","    # Each TP_FP dict stores the TP_FP for each class \n","    \n","    batch_total_TP = 0\n","    batch_total_FP = 0\n","    batch_total_FN = 0\n","    batch_total_num_object = 0\n","    j = 0\n","    for pred_bbox, pred_label, pred_score, gt_bbox, gt_label in \\\n","    zip(pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels):\n","\n","        pred_bbox = np.array(pred_bbox)\n","        pred_score = np.array(pred_score)\n","        pred_label = np.array(pred_label)\n","        gt_bbox = np.array(gt_bbox)\n","        gt_label = np.array(gt_label)\n","        unique_share_classes = (np.unique(np.concatenate((pred_label, gt_label))))\n","        #print(unique_share_classes)\n","        \n","        for c in unique_share_classes:\n","            # Get all the predicted bounding boxes of class c\n","\n","            pred_class_c_index = np.where(pred_label == c)[0]\n","            pred_bbox_c = pred_bbox[pred_class_c_index]\n","            gt_class_c_index = np.where(gt_label == c)[0]\n","            #print(gt_class_c_index)\n","            gt_bbox_c = gt_bbox[gt_class_c_index]\n","            num_gt_boxes = len(gt_class_c_index)\n","            num_pred_bboxes = len(pred_class_c_index)\n","            # print('class {}'.format(c))\n","            # print('num predicted bbox for this class {}'.format(num_pred_bboxes))\n","            # print('num gt bbox for this class {} {}'.format(c, len(gt_class_c_index)))\n","\n","            if len(pred_class_c_index) == 0:\n","                class_TP = 0\n","                class_FP = 0\n","                class_FN = num_gt_boxes\n","            elif len(gt_class_c_index) == 0:\n","                class_TP = 0\n","                class_FP = num_pred_bboxes\n","                class_FN = 0\n","            else:\n","                class_TP, class_FP = cal_TP_FP_iou(pred_bbox_c, gt_bbox_c, iou_thres)\n","                class_FN = num_gt_boxes - class_TP\n","                \n","\n","            batch_total_TP += class_TP\n","            batch_total_FP += class_FP\n","            batch_total_FN += class_FN\n","            batch_total_num_object += num_gt_boxes\n","\n","            res[c]['TP'] += class_TP\n","            res[c]['FP'] += class_FP\n","            res[c]['FN'] += class_FN\n","            \n","    return res, batch_total_TP, batch_total_FP, batch_total_FN, batch_total_num_object"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nji9KKjySsLT","colab_type":"code","colab":{}},"source":["test_images, test_targets = next(iter(test_loader))\n","test_images = torch.stack(test_images)\n","#print(test_images.shape)\n","test_images = prepare_inputs(test_images)\n","#print(test_images[0].shape)\n","\n","test_images = list(image.to(device) for image in test_images)\n","test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","model.eval()\n","predictions = model(test_images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfzs9R0nS5Wr","colab_type":"code","colab":{}},"source":["res, batch_total_TP, batch_total_FP, batch_total_FN, batch_total_num_ob \\\n"," = evaluate_one_batch(predictions, test_targets, iou_thres=0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhl7niyU3psc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"72b343a3-6a3d-4d84-ad9e-69ff3da2cc58","executionInfo":{"status":"ok","timestamp":1587677127103,"user_tz":240,"elapsed":379,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["batch_total_num_ob"],"execution_count":369,"outputs":[{"output_type":"execute_result","data":{"text/plain":["31"]},"metadata":{"tags":[]},"execution_count":369}]},{"cell_type":"code","metadata":{"id":"5Hf3Cii6S5gf","colab_type":"code","colab":{}},"source":["def evaluate_one_epoch(test_loader, iou_thres=0.5):\n","    # Evaluate. for all data point in the evaluaton set\n","    final_res = {c: {'TP':0, 'FP': 0, 'FN': 0} for c in range(9)}\n","    final_TP = 0\n","    final_FP = 0\n","    final_FN = 0\n","    final_num_objects = 0\n","\n","    for iter_, (test_images, test_targets) in enumerate(test_loader):\n","        if iter_ % 50 == 0:\n","            print('iter', iter_)\n","        #print('iter', iter_)\n","        test_images = torch.stack(test_images)\n","        #print(test_images.shape)\n","        test_images = prepare_inputs(test_images)\n","        #print(test_images[0].shape)\n","\n","        test_images = list(image.to(device) for image in test_images)\n","        test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","        model.eval()\n","        predictions = model(test_images)\n","\n","        # Evaluate for one batch\n","        final_res, batch_total_TP, batch_total_FP, batch_total_FN, batch_total_num_ob = evaluate_one_batch(predictions, \n","                                                                                test_targets,\n","                                                                                iou_thres,\n","                                                                                final_res)\n","        \n","        final_TP += batch_total_TP\n","        final_FP += batch_total_FP\n","        final_FN += batch_total_FN\n","        final_num_objects += batch_total_num_ob\n","\n","    return final_res, final_TP, final_FP, final_FN, final_num_objects"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zop8Z75IS5ep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"6e4f6c7b-0dd6-4ac7-f132-18bb034923dd","executionInfo":{"status":"ok","timestamp":1587677257785,"user_tz":240,"elapsed":104687,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["final_res, final_TP, final_FP, final_FN, final_num_objects = evaluate_one_epoch(test_loader, iou_thres=0.5)"],"execution_count":373,"outputs":[{"output_type":"stream","text":["iter 0\n","iter 50\n","iter 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JFT09TgzS5cW","colab_type":"code","colab":{}},"source":["def evaluate_threst_score(TP, FP, FN):\n","    return (TP / (TP + FP + FN))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEx2ls44dlXz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f6bc8130-b1ba-4057-c0b5-8b0f79091f45","executionInfo":{"status":"ok","timestamp":1587677684835,"user_tz":240,"elapsed":345,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["evaluate_threst_score(final_TP, final_FP, final_FN)"],"execution_count":375,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":375}]},{"cell_type":"markdown","metadata":{"id":"ve5Zlqi-dvxf","colab_type":"text"},"source":["## Train and Evaluate for Multiple Epochs"]},{"cell_type":"code","metadata":{"id":"mm_4-JrdeH59","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                            momentum=0.9, weight_decay=0.0005)\n","# and a learning rate scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                step_size=3,\n","                                                gamma=0.1)\n","\n","# let's train it for 10 epochs\n","num_epochs = 10\n","epoch = 0\n","print_freq = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxJ2JfOufhEI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4fAgXgidudg","colab_type":"code","colab":{}},"source":["def train_eval(model, train_loader, test_loader, iou_thres=0.5, num_epochs=10):\n","    train_losses = []\n","    eval_threatscores = []\n","    eval_final_res = []\n","    best_eval_ts = 0\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    for epoch in range(num_epochs):\n","        loss = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq)\n","        train_losses.append(loss)\n","        final_res, final_TP, final_FP, final_FN, final_num_objects = evaluate_one_epoch(test_loader, iou_thres=0.5)\n","\n","        print(\"epoch: {}\".format(epoch))\n","        print(final_TP, final_FP, final_FN, final_num_objects)\n","        eval_final_res.append(final_res)\n","        eval_ts = evaluate_threst_score(final_TP, final_FP, final_FN)\n","        eval_threatscores.append(eval_ts)\n","        if epoch % 5 == 0:\n","            print(\"epoch: {} eval_ts {}\".format(epoch, eval_ts))\n","\n","        if eval_ts > best_eval_ts:\n","            best_eval_ts = eval_ts \n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    return model, best_model_wts, train_losses, eval_final_res"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OsAuhVThduhA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"71913a3e-051c-4a3f-badc-c0cce30aa412","executionInfo":{"status":"ok","timestamp":1587682820135,"user_tz":240,"elapsed":1120029,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["model, best_model_wts, train_losses, eval_final_res = train_eval(model, train_loader,\n","                                                                 test_loader, iou_thres=0.5,\n","                                                                 num_epochs=10)"],"execution_count":384,"outputs":[{"output_type":"stream","text":["Epoch: [0]  [  0/126]  eta: 0:05:44  lr: 0.000045  loss: 0.5844 (0.5844)  loss_classifier: 0.1467 (0.1467)  loss_box_reg: 0.0410 (0.0410)  loss_objectness: 0.0109 (0.0109)  loss_rpn_box_reg: 0.3859 (0.3859)  time: 2.7342  data: 0.3330  max mem: 8211\n","Epoch: [0]  [ 20/126]  eta: 0:03:29  lr: 0.000844  loss: 0.5529 (0.5374)  loss_classifier: 0.1355 (0.1373)  loss_box_reg: 0.0231 (0.0278)  loss_objectness: 0.0274 (0.0294)  loss_rpn_box_reg: 0.2927 (0.3429)  time: 1.9345  data: 0.0039  max mem: 8211\n","Epoch: [0]  [ 40/126]  eta: 0:02:48  lr: 0.001643  loss: 0.4008 (0.4897)  loss_classifier: 0.1311 (0.1392)  loss_box_reg: 0.0314 (0.0303)  loss_objectness: 0.0349 (0.0318)  loss_rpn_box_reg: 0.2269 (0.2884)  time: 1.9354  data: 0.0043  max mem: 8211\n","Epoch: [0]  [ 60/126]  eta: 0:02:08  lr: 0.002443  loss: 0.4872 (0.4817)  loss_classifier: 0.1397 (0.1413)  loss_box_reg: 0.0265 (0.0306)  loss_objectness: 0.0222 (0.0316)  loss_rpn_box_reg: 0.2503 (0.2782)  time: 1.9440  data: 0.0041  max mem: 8211\n","Epoch: [0]  [ 80/126]  eta: 0:01:29  lr: 0.003242  loss: 0.3907 (0.4641)  loss_classifier: 0.1112 (0.1357)  loss_box_reg: 0.0259 (0.0301)  loss_objectness: 0.0240 (0.0305)  loss_rpn_box_reg: 0.2266 (0.2677)  time: 1.9443  data: 0.0043  max mem: 8211\n","Epoch: [0]  [100/126]  eta: 0:00:50  lr: 0.004041  loss: 0.3973 (0.4635)  loss_classifier: 0.1031 (0.1371)  loss_box_reg: 0.0197 (0.0305)  loss_objectness: 0.0196 (0.0290)  loss_rpn_box_reg: 0.2682 (0.2668)  time: 1.9404  data: 0.0041  max mem: 8211\n","Epoch: [0]  [120/126]  eta: 0:00:11  lr: 0.004840  loss: 0.4957 (0.4715)  loss_classifier: 0.1525 (0.1406)  loss_box_reg: 0.0357 (0.0318)  loss_objectness: 0.0261 (0.0287)  loss_rpn_box_reg: 0.2760 (0.2704)  time: 1.9321  data: 0.0042  max mem: 8211\n","Epoch: [0]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.5060 (0.4738)  loss_classifier: 0.1527 (0.1408)  loss_box_reg: 0.0398 (0.0323)  loss_objectness: 0.0261 (0.0290)  loss_rpn_box_reg: 0.2782 (0.2717)  time: 1.9323  data: 0.0043  max mem: 8211\n","Epoch: [0] Total time: 0:04:05 (1.9455 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 5.0 2563.0 3664.0 3669\n","epoch: 0 eval_ts 0.0008023106546854943\n","Epoch: [1]  [  0/126]  eta: 0:05:37  lr: 0.005000  loss: 0.6536 (0.6536)  loss_classifier: 0.1903 (0.1903)  loss_box_reg: 0.0481 (0.0481)  loss_objectness: 0.0593 (0.0593)  loss_rpn_box_reg: 0.3558 (0.3558)  time: 2.6762  data: 0.3308  max mem: 8211\n","Epoch: [1]  [ 20/126]  eta: 0:03:30  lr: 0.005000  loss: 0.4338 (0.4748)  loss_classifier: 0.1229 (0.1307)  loss_box_reg: 0.0283 (0.0325)  loss_objectness: 0.0292 (0.0329)  loss_rpn_box_reg: 0.2780 (0.2786)  time: 1.9523  data: 0.0043  max mem: 8211\n","Epoch: [1]  [ 40/126]  eta: 0:02:48  lr: 0.005000  loss: 0.4609 (0.4691)  loss_classifier: 0.1184 (0.1354)  loss_box_reg: 0.0327 (0.0341)  loss_objectness: 0.0267 (0.0319)  loss_rpn_box_reg: 0.2724 (0.2677)  time: 1.9366  data: 0.0042  max mem: 8211\n","Epoch: [1]  [ 60/126]  eta: 0:02:09  lr: 0.005000  loss: 0.5376 (0.4964)  loss_classifier: 0.1332 (0.1351)  loss_box_reg: 0.0296 (0.0341)  loss_objectness: 0.0309 (0.0332)  loss_rpn_box_reg: 0.3441 (0.2940)  time: 1.9577  data: 0.0045  max mem: 8211\n","Epoch: [1]  [ 80/126]  eta: 0:01:30  lr: 0.005000  loss: 0.4477 (0.4895)  loss_classifier: 0.1018 (0.1337)  loss_box_reg: 0.0257 (0.0333)  loss_objectness: 0.0231 (0.0315)  loss_rpn_box_reg: 0.2889 (0.2911)  time: 1.9460  data: 0.0045  max mem: 8211\n","Epoch: [1]  [100/126]  eta: 0:00:50  lr: 0.005000  loss: 0.5135 (0.4929)  loss_classifier: 0.1404 (0.1338)  loss_box_reg: 0.0284 (0.0329)  loss_objectness: 0.0172 (0.0309)  loss_rpn_box_reg: 0.3117 (0.2954)  time: 1.9503  data: 0.0045  max mem: 8211\n","Epoch: [1]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.4833 (0.4877)  loss_classifier: 0.1098 (0.1320)  loss_box_reg: 0.0343 (0.0332)  loss_objectness: 0.0326 (0.0312)  loss_rpn_box_reg: 0.2608 (0.2913)  time: 1.9681  data: 0.0045  max mem: 8211\n","Epoch: [1]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.4833 (0.4894)  loss_classifier: 0.1442 (0.1339)  loss_box_reg: 0.0353 (0.0338)  loss_objectness: 0.0289 (0.0311)  loss_rpn_box_reg: 0.2608 (0.2906)  time: 1.9641  data: 0.0045  max mem: 8211\n","Epoch: [1] Total time: 0:04:06 (1.9591 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 9.0 12591.0 3660.0 3669\n","Epoch: [2]  [  0/126]  eta: 0:05:37  lr: 0.005000  loss: 0.3620 (0.3620)  loss_classifier: 0.0920 (0.0920)  loss_box_reg: 0.0134 (0.0134)  loss_objectness: 0.0124 (0.0124)  loss_rpn_box_reg: 0.2442 (0.2442)  time: 2.6788  data: 0.3522  max mem: 8211\n","Epoch: [2]  [ 20/126]  eta: 0:03:29  lr: 0.005000  loss: 0.4255 (0.4363)  loss_classifier: 0.1086 (0.1281)  loss_box_reg: 0.0352 (0.0354)  loss_objectness: 0.0242 (0.0275)  loss_rpn_box_reg: 0.2400 (0.2452)  time: 1.9384  data: 0.0043  max mem: 8211\n","Epoch: [2]  [ 40/126]  eta: 0:02:48  lr: 0.005000  loss: 0.4221 (0.4409)  loss_classifier: 0.1205 (0.1283)  loss_box_reg: 0.0297 (0.0342)  loss_objectness: 0.0404 (0.0333)  loss_rpn_box_reg: 0.2401 (0.2451)  time: 1.9373  data: 0.0047  max mem: 8211\n","Epoch: [2]  [ 60/126]  eta: 0:02:08  lr: 0.005000  loss: 0.4811 (0.4557)  loss_classifier: 0.1286 (0.1331)  loss_box_reg: 0.0389 (0.0363)  loss_objectness: 0.0334 (0.0338)  loss_rpn_box_reg: 0.2641 (0.2525)  time: 1.9355  data: 0.0042  max mem: 8211\n","Epoch: [2]  [ 80/126]  eta: 0:01:29  lr: 0.005000  loss: 0.4564 (0.4606)  loss_classifier: 0.1368 (0.1321)  loss_box_reg: 0.0258 (0.0349)  loss_objectness: 0.0354 (0.0345)  loss_rpn_box_reg: 0.2510 (0.2591)  time: 1.9409  data: 0.0043  max mem: 8211\n","Epoch: [2]  [100/126]  eta: 0:00:50  lr: 0.005000  loss: 0.3945 (0.4527)  loss_classifier: 0.1162 (0.1313)  loss_box_reg: 0.0293 (0.0351)  loss_objectness: 0.0254 (0.0323)  loss_rpn_box_reg: 0.2314 (0.2540)  time: 1.9527  data: 0.0044  max mem: 8211\n","Epoch: [2]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.4806 (0.4582)  loss_classifier: 0.1509 (0.1338)  loss_box_reg: 0.0348 (0.0352)  loss_objectness: 0.0218 (0.0321)  loss_rpn_box_reg: 0.2566 (0.2571)  time: 1.9566  data: 0.0046  max mem: 8211\n","Epoch: [2]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.4940 (0.4602)  loss_classifier: 0.1476 (0.1333)  loss_box_reg: 0.0347 (0.0348)  loss_objectness: 0.0271 (0.0325)  loss_rpn_box_reg: 0.2862 (0.2596)  time: 1.9528  data: 0.0045  max mem: 8211\n","Epoch: [2] Total time: 0:04:05 (1.9508 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 2.0 5268.0 3667.0 3669\n","Epoch: [3]  [  0/126]  eta: 0:05:37  lr: 0.005000  loss: 0.2535 (0.2535)  loss_classifier: 0.0408 (0.0408)  loss_box_reg: 0.0020 (0.0020)  loss_objectness: 0.0372 (0.0372)  loss_rpn_box_reg: 0.1735 (0.1735)  time: 2.6754  data: 0.3325  max mem: 8211\n","Epoch: [3]  [ 20/126]  eta: 0:03:31  lr: 0.005000  loss: 0.4888 (0.4719)  loss_classifier: 0.1419 (0.1349)  loss_box_reg: 0.0316 (0.0350)  loss_objectness: 0.0285 (0.0280)  loss_rpn_box_reg: 0.2705 (0.2739)  time: 1.9573  data: 0.0044  max mem: 8211\n","Epoch: [3]  [ 40/126]  eta: 0:02:49  lr: 0.005000  loss: 0.4761 (0.4690)  loss_classifier: 0.1236 (0.1379)  loss_box_reg: 0.0314 (0.0345)  loss_objectness: 0.0236 (0.0266)  loss_rpn_box_reg: 0.2468 (0.2701)  time: 1.9524  data: 0.0041  max mem: 8211\n","Epoch: [3]  [ 60/126]  eta: 0:02:09  lr: 0.005000  loss: 0.4347 (0.4583)  loss_classifier: 0.1033 (0.1338)  loss_box_reg: 0.0307 (0.0343)  loss_objectness: 0.0209 (0.0272)  loss_rpn_box_reg: 0.2396 (0.2630)  time: 1.9547  data: 0.0042  max mem: 8211\n","Epoch: [3]  [ 80/126]  eta: 0:01:30  lr: 0.005000  loss: 0.3975 (0.4454)  loss_classifier: 0.1069 (0.1296)  loss_box_reg: 0.0271 (0.0336)  loss_objectness: 0.0255 (0.0278)  loss_rpn_box_reg: 0.2238 (0.2543)  time: 1.9731  data: 0.0046  max mem: 8211\n","Epoch: [3]  [100/126]  eta: 0:00:51  lr: 0.005000  loss: 0.3924 (0.4442)  loss_classifier: 0.1069 (0.1296)  loss_box_reg: 0.0287 (0.0338)  loss_objectness: 0.0255 (0.0283)  loss_rpn_box_reg: 0.2392 (0.2525)  time: 1.9686  data: 0.0043  max mem: 8211\n","Epoch: [3]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.4606 (0.4466)  loss_classifier: 0.1071 (0.1271)  loss_box_reg: 0.0319 (0.0338)  loss_objectness: 0.0227 (0.0289)  loss_rpn_box_reg: 0.2703 (0.2569)  time: 1.9715  data: 0.0047  max mem: 8211\n","Epoch: [3]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.4777 (0.4453)  loss_classifier: 0.1205 (0.1265)  loss_box_reg: 0.0331 (0.0341)  loss_objectness: 0.0232 (0.0291)  loss_rpn_box_reg: 0.2742 (0.2556)  time: 1.9634  data: 0.0046  max mem: 8211\n","Epoch: [3] Total time: 0:04:08 (1.9695 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 13.0 8843.0 3656.0 3669\n","Epoch: [4]  [  0/126]  eta: 0:05:38  lr: 0.005000  loss: 0.6285 (0.6285)  loss_classifier: 0.2304 (0.2304)  loss_box_reg: 0.0685 (0.0685)  loss_objectness: 0.0588 (0.0588)  loss_rpn_box_reg: 0.2708 (0.2708)  time: 2.6876  data: 0.3503  max mem: 8211\n","Epoch: [4]  [ 20/126]  eta: 0:03:31  lr: 0.005000  loss: 0.4688 (0.4659)  loss_classifier: 0.1408 (0.1494)  loss_box_reg: 0.0372 (0.0436)  loss_objectness: 0.0300 (0.0370)  loss_rpn_box_reg: 0.2401 (0.2359)  time: 1.9633  data: 0.0046  max mem: 8211\n","Epoch: [4]  [ 40/126]  eta: 0:02:49  lr: 0.005000  loss: 0.3903 (0.4482)  loss_classifier: 0.1084 (0.1389)  loss_box_reg: 0.0223 (0.0379)  loss_objectness: 0.0331 (0.0355)  loss_rpn_box_reg: 0.2220 (0.2359)  time: 1.9516  data: 0.0041  max mem: 8211\n","Epoch: [4]  [ 60/126]  eta: 0:02:10  lr: 0.005000  loss: 0.5093 (0.4724)  loss_classifier: 0.1368 (0.1410)  loss_box_reg: 0.0398 (0.0387)  loss_objectness: 0.0268 (0.0344)  loss_rpn_box_reg: 0.2838 (0.2583)  time: 1.9660  data: 0.0044  max mem: 8211\n","Epoch: [4]  [ 80/126]  eta: 0:01:30  lr: 0.005000  loss: 0.4145 (0.4639)  loss_classifier: 0.0977 (0.1334)  loss_box_reg: 0.0303 (0.0372)  loss_objectness: 0.0259 (0.0332)  loss_rpn_box_reg: 0.2591 (0.2601)  time: 1.9613  data: 0.0045  max mem: 8211\n","Epoch: [4]  [100/126]  eta: 0:00:51  lr: 0.005000  loss: 0.4129 (0.4575)  loss_classifier: 0.0878 (0.1291)  loss_box_reg: 0.0346 (0.0367)  loss_objectness: 0.0224 (0.0323)  loss_rpn_box_reg: 0.2539 (0.2594)  time: 1.9629  data: 0.0044  max mem: 8211\n","Epoch: [4]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.4476 (0.4553)  loss_classifier: 0.1088 (0.1292)  loss_box_reg: 0.0269 (0.0367)  loss_objectness: 0.0270 (0.0317)  loss_rpn_box_reg: 0.2321 (0.2577)  time: 1.9649  data: 0.0045  max mem: 8211\n","Epoch: [4]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.4022 (0.4517)  loss_classifier: 0.0926 (0.1280)  loss_box_reg: 0.0231 (0.0364)  loss_objectness: 0.0231 (0.0314)  loss_rpn_box_reg: 0.2238 (0.2559)  time: 1.9568  data: 0.0044  max mem: 8211\n","Epoch: [4] Total time: 0:04:07 (1.9678 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 5.0 12594.0 3664.0 3669\n","Epoch: [5]  [  0/126]  eta: 0:05:33  lr: 0.005000  loss: 0.5472 (0.5472)  loss_classifier: 0.1752 (0.1752)  loss_box_reg: 0.0657 (0.0657)  loss_objectness: 0.0338 (0.0338)  loss_rpn_box_reg: 0.2725 (0.2725)  time: 2.6450  data: 0.3281  max mem: 8211\n","Epoch: [5]  [ 20/126]  eta: 0:03:29  lr: 0.005000  loss: 0.4243 (0.4288)  loss_classifier: 0.1097 (0.1295)  loss_box_reg: 0.0330 (0.0383)  loss_objectness: 0.0212 (0.0294)  loss_rpn_box_reg: 0.2247 (0.2316)  time: 1.9459  data: 0.0044  max mem: 8211\n","Epoch: [5]  [ 40/126]  eta: 0:02:49  lr: 0.005000  loss: 0.4389 (0.4234)  loss_classifier: 0.1254 (0.1272)  loss_box_reg: 0.0276 (0.0352)  loss_objectness: 0.0269 (0.0287)  loss_rpn_box_reg: 0.2435 (0.2324)  time: 1.9514  data: 0.0044  max mem: 8211\n","Epoch: [5]  [ 60/126]  eta: 0:02:09  lr: 0.005000  loss: 0.4463 (0.4371)  loss_classifier: 0.1213 (0.1259)  loss_box_reg: 0.0267 (0.0350)  loss_objectness: 0.0269 (0.0291)  loss_rpn_box_reg: 0.2589 (0.2471)  time: 1.9631  data: 0.0045  max mem: 8211\n","Epoch: [5]  [ 80/126]  eta: 0:01:30  lr: 0.005000  loss: 0.3669 (0.4295)  loss_classifier: 0.0915 (0.1240)  loss_box_reg: 0.0346 (0.0356)  loss_objectness: 0.0283 (0.0293)  loss_rpn_box_reg: 0.2208 (0.2406)  time: 1.9597  data: 0.0041  max mem: 8211\n","Epoch: [5]  [100/126]  eta: 0:00:50  lr: 0.005000  loss: 0.3856 (0.4276)  loss_classifier: 0.1052 (0.1225)  loss_box_reg: 0.0299 (0.0359)  loss_objectness: 0.0351 (0.0307)  loss_rpn_box_reg: 0.2202 (0.2385)  time: 1.9421  data: 0.0043  max mem: 8211\n","Epoch: [5]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.3912 (0.4256)  loss_classifier: 0.0981 (0.1217)  loss_box_reg: 0.0354 (0.0359)  loss_objectness: 0.0224 (0.0297)  loss_rpn_box_reg: 0.2258 (0.2383)  time: 1.9431  data: 0.0044  max mem: 8211\n","Epoch: [5]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.4562 (0.4301)  loss_classifier: 0.1255 (0.1238)  loss_box_reg: 0.0375 (0.0369)  loss_objectness: 0.0255 (0.0296)  loss_rpn_box_reg: 0.2387 (0.2398)  time: 1.9397  data: 0.0043  max mem: 8211\n","Epoch: [5] Total time: 0:04:06 (1.9572 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 7.0 12593.0 3662.0 3669\n","epoch: 5 eval_ts 0.0004304513589964334\n","Epoch: [6]  [  0/126]  eta: 0:05:33  lr: 0.005000  loss: 0.4233 (0.4233)  loss_classifier: 0.1074 (0.1074)  loss_box_reg: 0.0255 (0.0255)  loss_objectness: 0.0577 (0.0577)  loss_rpn_box_reg: 0.2327 (0.2327)  time: 2.6491  data: 0.3429  max mem: 8211\n","Epoch: [6]  [ 20/126]  eta: 0:03:30  lr: 0.005000  loss: 0.3910 (0.4264)  loss_classifier: 0.1148 (0.1198)  loss_box_reg: 0.0376 (0.0404)  loss_objectness: 0.0262 (0.0270)  loss_rpn_box_reg: 0.2287 (0.2392)  time: 1.9530  data: 0.0041  max mem: 8211\n","Epoch: [6]  [ 40/126]  eta: 0:02:49  lr: 0.005000  loss: 0.4275 (0.4243)  loss_classifier: 0.0925 (0.1135)  loss_box_reg: 0.0282 (0.0368)  loss_objectness: 0.0326 (0.0302)  loss_rpn_box_reg: 0.2486 (0.2438)  time: 1.9599  data: 0.0041  max mem: 8211\n","Epoch: [6]  [ 60/126]  eta: 0:02:09  lr: 0.005000  loss: 0.4602 (0.4326)  loss_classifier: 0.1373 (0.1187)  loss_box_reg: 0.0371 (0.0382)  loss_objectness: 0.0339 (0.0316)  loss_rpn_box_reg: 0.2273 (0.2441)  time: 1.9549  data: 0.0047  max mem: 8211\n","Epoch: [6]  [ 80/126]  eta: 0:01:30  lr: 0.005000  loss: 0.4474 (0.4330)  loss_classifier: 0.0891 (0.1177)  loss_box_reg: 0.0260 (0.0372)  loss_objectness: 0.0273 (0.0324)  loss_rpn_box_reg: 0.2504 (0.2458)  time: 1.9613  data: 0.0044  max mem: 8211\n","Epoch: [6]  [100/126]  eta: 0:00:51  lr: 0.005000  loss: 0.4131 (0.4292)  loss_classifier: 0.1131 (0.1187)  loss_box_reg: 0.0328 (0.0373)  loss_objectness: 0.0199 (0.0301)  loss_rpn_box_reg: 0.2319 (0.2431)  time: 1.9643  data: 0.0044  max mem: 8211\n","Epoch: [6]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.4175 (0.4264)  loss_classifier: 0.1187 (0.1182)  loss_box_reg: 0.0240 (0.0363)  loss_objectness: 0.0223 (0.0298)  loss_rpn_box_reg: 0.2296 (0.2420)  time: 1.9569  data: 0.0043  max mem: 8211\n","Epoch: [6]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.4238 (0.4266)  loss_classifier: 0.1083 (0.1180)  loss_box_reg: 0.0262 (0.0362)  loss_objectness: 0.0246 (0.0299)  loss_rpn_box_reg: 0.2378 (0.2425)  time: 1.9511  data: 0.0043  max mem: 8211\n","Epoch: [6] Total time: 0:04:07 (1.9651 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 11.0 6536.0 3658.0 3669\n","Epoch: [7]  [  0/126]  eta: 0:05:36  lr: 0.005000  loss: 0.2608 (0.2608)  loss_classifier: 0.0409 (0.0409)  loss_box_reg: 0.0153 (0.0153)  loss_objectness: 0.0750 (0.0750)  loss_rpn_box_reg: 0.1295 (0.1295)  time: 2.6694  data: 0.3358  max mem: 8211\n","Epoch: [7]  [ 20/126]  eta: 0:03:29  lr: 0.005000  loss: 0.4212 (0.4289)  loss_classifier: 0.1201 (0.1153)  loss_box_reg: 0.0348 (0.0389)  loss_objectness: 0.0272 (0.0350)  loss_rpn_box_reg: 0.2528 (0.2398)  time: 1.9458  data: 0.0044  max mem: 8211\n","Epoch: [7]  [ 40/126]  eta: 0:02:48  lr: 0.005000  loss: 0.4073 (0.4399)  loss_classifier: 0.1147 (0.1224)  loss_box_reg: 0.0342 (0.0396)  loss_objectness: 0.0262 (0.0326)  loss_rpn_box_reg: 0.2525 (0.2452)  time: 1.9379  data: 0.0043  max mem: 8211\n","Epoch: [7]  [ 60/126]  eta: 0:02:08  lr: 0.005000  loss: 0.4484 (0.4460)  loss_classifier: 0.1105 (0.1223)  loss_box_reg: 0.0351 (0.0405)  loss_objectness: 0.0246 (0.0312)  loss_rpn_box_reg: 0.2560 (0.2521)  time: 1.9374  data: 0.0045  max mem: 8211\n","Epoch: [7]  [ 80/126]  eta: 0:01:29  lr: 0.005000  loss: 0.4145 (0.4399)  loss_classifier: 0.1161 (0.1226)  loss_box_reg: 0.0304 (0.0396)  loss_objectness: 0.0229 (0.0302)  loss_rpn_box_reg: 0.2290 (0.2475)  time: 1.9442  data: 0.0042  max mem: 8211\n","Epoch: [7]  [100/126]  eta: 0:00:50  lr: 0.005000  loss: 0.4518 (0.4435)  loss_classifier: 0.1364 (0.1272)  loss_box_reg: 0.0367 (0.0409)  loss_objectness: 0.0243 (0.0297)  loss_rpn_box_reg: 0.2239 (0.2457)  time: 1.9393  data: 0.0046  max mem: 8211\n","Epoch: [7]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.3212 (0.4300)  loss_classifier: 0.0957 (0.1236)  loss_box_reg: 0.0277 (0.0401)  loss_objectness: 0.0189 (0.0289)  loss_rpn_box_reg: 0.1846 (0.2375)  time: 1.9467  data: 0.0045  max mem: 8211\n","Epoch: [7]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.3143 (0.4305)  loss_classifier: 0.0870 (0.1233)  loss_box_reg: 0.0267 (0.0396)  loss_objectness: 0.0180 (0.0288)  loss_rpn_box_reg: 0.1827 (0.2389)  time: 1.9509  data: 0.0046  max mem: 8211\n","Epoch: [7] Total time: 0:04:05 (1.9498 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 4.0 11197.0 3665.0 3669\n","Epoch: [8]  [  0/126]  eta: 0:05:37  lr: 0.005000  loss: 0.2828 (0.2828)  loss_classifier: 0.0546 (0.0546)  loss_box_reg: 0.0108 (0.0108)  loss_objectness: 0.0258 (0.0258)  loss_rpn_box_reg: 0.1916 (0.1916)  time: 2.6805  data: 0.3469  max mem: 8211\n","Epoch: [8]  [ 20/126]  eta: 0:03:32  lr: 0.005000  loss: 0.3772 (0.3864)  loss_classifier: 0.0972 (0.0998)  loss_box_reg: 0.0242 (0.0280)  loss_objectness: 0.0223 (0.0235)  loss_rpn_box_reg: 0.2372 (0.2351)  time: 1.9709  data: 0.0042  max mem: 8211\n","Epoch: [8]  [ 40/126]  eta: 0:02:50  lr: 0.005000  loss: 0.3908 (0.4021)  loss_classifier: 0.0896 (0.1016)  loss_box_reg: 0.0259 (0.0296)  loss_objectness: 0.0233 (0.0278)  loss_rpn_box_reg: 0.2484 (0.2431)  time: 1.9629  data: 0.0046  max mem: 8211\n","Epoch: [8]  [ 60/126]  eta: 0:02:10  lr: 0.005000  loss: 0.3887 (0.4110)  loss_classifier: 0.1154 (0.1098)  loss_box_reg: 0.0260 (0.0335)  loss_objectness: 0.0182 (0.0279)  loss_rpn_box_reg: 0.2242 (0.2398)  time: 1.9622  data: 0.0045  max mem: 8211\n","Epoch: [8]  [ 80/126]  eta: 0:01:30  lr: 0.005000  loss: 0.4313 (0.4096)  loss_classifier: 0.1135 (0.1103)  loss_box_reg: 0.0317 (0.0327)  loss_objectness: 0.0222 (0.0286)  loss_rpn_box_reg: 0.2299 (0.2380)  time: 1.9593  data: 0.0044  max mem: 8211\n","Epoch: [8]  [100/126]  eta: 0:00:51  lr: 0.005000  loss: 0.3971 (0.4088)  loss_classifier: 0.1048 (0.1110)  loss_box_reg: 0.0283 (0.0332)  loss_objectness: 0.0243 (0.0284)  loss_rpn_box_reg: 0.2301 (0.2362)  time: 1.9610  data: 0.0044  max mem: 8211\n","Epoch: [8]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.4173 (0.4114)  loss_classifier: 0.0907 (0.1104)  loss_box_reg: 0.0255 (0.0328)  loss_objectness: 0.0231 (0.0287)  loss_rpn_box_reg: 0.2321 (0.2395)  time: 1.9624  data: 0.0047  max mem: 8211\n","Epoch: [8]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.4100 (0.4104)  loss_classifier: 0.1059 (0.1108)  loss_box_reg: 0.0287 (0.0330)  loss_objectness: 0.0212 (0.0284)  loss_rpn_box_reg: 0.2271 (0.2383)  time: 1.9614  data: 0.0045  max mem: 8211\n","Epoch: [8] Total time: 0:04:08 (1.9698 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 4.0 12596.0 3665.0 3669\n","Epoch: [9]  [  0/126]  eta: 0:05:42  lr: 0.005000  loss: 0.4773 (0.4773)  loss_classifier: 0.1611 (0.1611)  loss_box_reg: 0.0412 (0.0412)  loss_objectness: 0.0318 (0.0318)  loss_rpn_box_reg: 0.2431 (0.2431)  time: 2.7165  data: 0.3528  max mem: 8211\n","Epoch: [9]  [ 20/126]  eta: 0:03:34  lr: 0.005000  loss: 0.3572 (0.3747)  loss_classifier: 0.0834 (0.1001)  loss_box_reg: 0.0239 (0.0287)  loss_objectness: 0.0215 (0.0216)  loss_rpn_box_reg: 0.2221 (0.2243)  time: 1.9870  data: 0.0043  max mem: 8211\n","Epoch: [9]  [ 40/126]  eta: 0:02:52  lr: 0.005000  loss: 0.3576 (0.3874)  loss_classifier: 0.0868 (0.1015)  loss_box_reg: 0.0247 (0.0299)  loss_objectness: 0.0253 (0.0263)  loss_rpn_box_reg: 0.2169 (0.2297)  time: 1.9840  data: 0.0044  max mem: 8211\n","Epoch: [9]  [ 60/126]  eta: 0:02:11  lr: 0.005000  loss: 0.4735 (0.4141)  loss_classifier: 0.1345 (0.1133)  loss_box_reg: 0.0356 (0.0359)  loss_objectness: 0.0277 (0.0274)  loss_rpn_box_reg: 0.2535 (0.2375)  time: 1.9911  data: 0.0047  max mem: 8211\n","Epoch: [9]  [ 80/126]  eta: 0:01:31  lr: 0.005000  loss: 0.4260 (0.4151)  loss_classifier: 0.1133 (0.1134)  loss_box_reg: 0.0301 (0.0362)  loss_objectness: 0.0251 (0.0277)  loss_rpn_box_reg: 0.2282 (0.2378)  time: 1.9861  data: 0.0045  max mem: 8211\n","Epoch: [9]  [100/126]  eta: 0:00:51  lr: 0.005000  loss: 0.3378 (0.4072)  loss_classifier: 0.0765 (0.1099)  loss_box_reg: 0.0245 (0.0342)  loss_objectness: 0.0295 (0.0281)  loss_rpn_box_reg: 0.2170 (0.2349)  time: 1.9617  data: 0.0045  max mem: 8211\n","Epoch: [9]  [120/126]  eta: 0:00:11  lr: 0.005000  loss: 0.4133 (0.4067)  loss_classifier: 0.1045 (0.1102)  loss_box_reg: 0.0323 (0.0349)  loss_objectness: 0.0236 (0.0275)  loss_rpn_box_reg: 0.2232 (0.2341)  time: 1.9613  data: 0.0044  max mem: 8211\n","Epoch: [9]  [125/126]  eta: 0:00:01  lr: 0.005000  loss: 0.4195 (0.4080)  loss_classifier: 0.1052 (0.1104)  loss_box_reg: 0.0313 (0.0347)  loss_objectness: 0.0259 (0.0278)  loss_rpn_box_reg: 0.2434 (0.2351)  time: 1.9601  data: 0.0044  max mem: 8211\n","Epoch: [9] Total time: 0:04:10 (1.9848 s / it)\n","iter 0\n","iter 50\n","iter 100\n","epoch: {} 4.0 12596.0 3665.0 3669\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Naw6li0b09RY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"bbc50d08-b1e1-499b-a02d-a506fe33ca1b","executionInfo":{"status":"ok","timestamp":1587682820137,"user_tz":240,"elapsed":23,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["eval_final_res"],"execution_count":385,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3069.0, 'FP': 2563.0, 'TP': 5.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3065.0, 'FP': 12591.0, 'TP': 9.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3072.0, 'FP': 5268.0, 'TP': 2.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3061.0, 'FP': 8843.0, 'TP': 13.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3069.0, 'FP': 12594.0, 'TP': 5.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3067.0, 'FP': 12593.0, 'TP': 7.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3063.0, 'FP': 6536.0, 'TP': 11.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3070.0, 'FP': 11197.0, 'TP': 4.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3070.0, 'FP': 12596.0, 'TP': 4.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3070.0, 'FP': 12596.0, 'TP': 4.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}}]"]},"metadata":{"tags":[]},"execution_count":385}]},{"cell_type":"code","metadata":{"id":"DlPUDruY09M6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"fb88fa50-a1d1-4336-9802-ff5c60c3f325","executionInfo":{"status":"ok","timestamp":1587679121033,"user_tz":240,"elapsed":519,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["train_losses\n"],"execution_count":383,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor(0.8429, device='cuda:0', grad_fn=<AddBackward0>),\n"," tensor(0.5462, device='cuda:0', grad_fn=<AddBackward0>),\n"," tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)]"]},"metadata":{"tags":[]},"execution_count":383}]},{"cell_type":"code","metadata":{"id":"pXmfiNDgJRY-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"aaeffc31-aa15-44d0-9d0a-61b203f837f1","executionInfo":{"status":"ok","timestamp":1587666212852,"user_tz":240,"elapsed":351,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["# res stores the TP_FP dict for each sample in the batch\n","# Each TP_FP dict stores the TP_FP for each class \n","res = []\n","batch_total_TP = 0\n","batch_total_FP = 0\n","batch_total_FN = 0\n","j = 0\n","for pred_bbox, pred_label, pred_score, gt_bbox, gt_label in \\\n","zip(pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels):\n","\n","    pred_bbox = np.array(pred_bbox)\n","    pred_score = np.array(pred_score)\n","    pred_label = np.array(pred_label)\n","    gt_bbox = np.array(gt_bbox)\n","    gt_label = np.array(gt_label)\n","    unique_share_classes = (np.unique(np.concatenate((pred_label, gt_label))))\n","    #print(unique_share_classes)\n","    TP_FP_class = {}\n","    for c in unique_share_classes:\n","        # Get all the predicted bounding boxes of class c\n","\n","        pred_class_c_index = np.where(pred_label == c)[0]\n","        pred_bbox_c = pred_bbox[pred_class_c_index]\n","        gt_class_c_index = np.where(gt_label == c)[0]\n","        #print(gt_class_c_index)\n","        gt_bbox_c = gt_bbox[gt_class_c_index]\n","        npos = len(gt_class_c_index)\n","        print('class {}'.format(c))\n","        print('num predicted bbox for this class {}'.format(len(pred_class_c_index)))\n","        print('num gt bbox for this class {}'.format(len(gt_class_c_index)))\n","\n","        iou_table = bbox_iou(pred_bbox_c, gt_bbox_c)\n","        num_pred_bboxes = iou_table.shape[0]\n","        num_gt_bboxes = iou_table.shape[1]\n","        TP = np.zeros(len(pred_class_c_index))\n","        FP = np.zeros(len(pred_class_c_index))\n","        # For each pred_bounding box:\n","          # Find the most relevant gt_bbox (i.e., the gt_bbox with max IoU)\n","          # If IoU < threshold, then flag it as FP\n","          # If IoU >= threshold, then:\n","            # If that gt_bbox already has already matched with another pred_bbox:\n","              # Flag it as FP\n","            # Else:\n","              # Flag it as TP\n","\n","        # TP only happens if the pred_bbox mathes with a gt_bbox\n","\n","        for i in range(len(pred_class_c_index)):\n","            gt_bbox_index = np.argmax(iou_table[i])\n","            best_pred_bbox_index_for_selected_gt_bbox = np.argmax(iou_table[:,gt_bbox_index])\n","            if iou_table[i, gt_bbox_index] > iou_thres \\\n","                and gt_bbox_index == best_pred_bbox_index_for_selected_gt_bbox:\n","                TP[i] = 1\n","            else:\n","                FP[i] = 1\n","        TP_cum = np.sum(TP)\n","        FP_cum = np.sum(FP)\n","        FN_cum = npos - TP_cum\n","\n","        batch_total_TP += TP_cum\n","        batch_total_FP += FP_cum\n","        batch_total_FN += FN_cum\n","        #print(c)\n","\n","        TP_FP_class[c] = [TP_cum, FP_cum, FN_cum]\n","\n","    res.append(TP_FP_class)\n"],"execution_count":248,"outputs":[{"output_type":"stream","text":["class 0\n","num predicted bbox for this class 0\n","num gt bbox for this class 1\n","class 2\n","num predicted bbox for this class 4\n","num gt bbox for this class 27\n","class 3\n","num predicted bbox for this class 0\n","num gt bbox for this class 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bZCj9OMXrg6-","colab_type":"code","colab":{}},"source":["def evaluate_test_samples(model, test_images, test_targets):\n","  test_images = torch.stack(test_images)\n","  #print(test_images.shape)\n","  test_images = prepare_inputs(test_images)\n","  #print(test_images[0].shape)\n","\n","  test_images = list(image.to(device) for image in test_images)\n","  test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","  model.eval()\n","  predictions = model(test_images)\n","\n","  for i in range(len(predictions)):\n","      num_objects_predicted = len(predictions[i]['labels'])\n","      num_objects_gt = len(test_targets[i]['labels'])\n","      print('num object predicted: {}, num_object_ground_truth: {}'.format(num_objects_predicted, num_objects_gt))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i64fm2Ddye_H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"5ccacf57-22cd-4772-c071-f0793f6a10e8","executionInfo":{"status":"ok","timestamp":1587590986107,"user_tz":240,"elapsed":24130,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["for i in range(3):\n","    test_images, test_targets = next(iter(test_loader))\n","    evaluate_test_samples(model, test_images, test_targets)"],"execution_count":97,"outputs":[{"output_type":"stream","text":["num object predicted: 58, num_object_ground_truth: 17\n","num object predicted: 38, num_object_ground_truth: 27\n","num object predicted: 28, num_object_ground_truth: 20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hXslpd4-d-rQ","colab_type":"text"},"source":["## Customize Fast RCNN"]},{"cell_type":"code","metadata":{"id":"UGCMc2Ppd-rR","colab_type":"code","colab":{}},"source":["import torchvision\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_IC8olie21GE","colab_type":"text"},"source":["#### 1. Mobilenet_v2"]},{"cell_type":"code","metadata":{"id":"cukXGxWk1WtO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"1c2db8fe-1068-4235-9348-d70fcb3ea02b","executionInfo":{"status":"error","timestamp":1587575181204,"user_tz":240,"elapsed":934,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n","backbone.out_channels = 1280\n","anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n","                                    aspect_ratios=((0.5, 1.0, 2.0),))\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","                                                output_size=7,\n","                                                sampling_ratio=2)\n","model = torchvision.models.detection.faster_rcnn.FasterRCNN(backbone,\n","                    num_classes=21,\n","                    rpn_anchor_generator=anchor_generator,\n","                    box_roi_pool=roi_pooler)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-47b1e48fc071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n\u001b[1;32m      4\u001b[0m                                     aspect_ratios=((0.5, 1.0, 2.0),))\n\u001b[1;32m      5\u001b[0m roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"]}]},{"cell_type":"code","metadata":{"id":"jVBYaALa2xOK","colab_type":"code","colab":{}},"source":["model.eval()\n","x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n","predictions = model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7XYTwLa26Mk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmOGwmnO26uZ","colab_type":"text"},"source":["#### 2. CustomVGG16"]},{"cell_type":"code","metadata":{"id":"xqIB1q2yd-rl","colab_type":"code","colab":{}},"source":["def customize_VGG16():\n","    model = torchvision.models.vgg16(pretrained=True)\n","    \n","    features = list(model.features)[:30]\n","    classifier = model.classifier\n","    \n","    classifier = list(classifier)\n","    # delete the Linear layer\n","    del classifier[6]\n","    classifier = nn.Sequential(*classifier)\n","\n","    #freeze top4 conv layer\n","    for layer in features[:10]:\n","        for p in layer.parameters():\n","            p.requires_grad = False\n","    features = nn.Sequential(*features)\n","        \n","    return features, classifier\n","backbone, box_head = customize_VGG16()\n","backbone.out_channels = 512\n","anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n","                                           aspect_ratios=((0.5, 1.0, 2.0),))\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","                                                output_size=7,\n","                                                sampling_ratio=2)\n"],"execution_count":0,"outputs":[]}]}