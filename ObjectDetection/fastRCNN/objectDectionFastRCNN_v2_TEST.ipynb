{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"objectDectionFastRCNN_v2_TEST.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"dr0quibWAFdQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"166cf08e-da77-4254-b2e2-b5c02316ac88","executionInfo":{"status":"ok","timestamp":1588030661060,"user_tz":240,"elapsed":29034,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Kat4oW0AW9w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"14e93c4c-6ecd-4c8b-896c-15a1a0397e5f","executionInfo":{"status":"ok","timestamp":1588030722482,"user_tz":240,"elapsed":5002,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["import os\n","!ls \n","os.chdir('gdrive/My Drive/dl20/final_project/FinalProject/fastRCNN')\n","\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["gdrive\tsample_data\n","data_helper.py\t      objectDectionFastRCNN_042020.ipynb   __pycache__\n","helper.py\t      objectDectionFastRCNN_042720.ipynb   run_test.py\n","model_loader.py       objectDectionFastRCNN_v2.ipynb\t   transforms.py\n","nhung_data_helper.py  objectDectionFastRCNN_v2_TEST.ipynb  utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n8JLihvjARxV","colab_type":"code","colab":{}},"source":["import sys\n","import os\n","#os.chdir('/scratch/nhl256/dl_project/code/')\n","\n","import random\n","import argparse\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","from data_helper import LabeledDataset\n","from helper import *\n","\n","import math\n","import time\n","\n","import utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVJEcFDd_1lC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8a51a1df-eb5d-4fa6-bcc5-d3271c592094","executionInfo":{"status":"ok","timestamp":1588030930599,"user_tz":240,"elapsed":207,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["sys.path.append('gdrive/My Drive/dl20/final_project/FinalProject/data/labeled')\n","sys.path.append('gdrive/My Drive/dl20/final_project/FinalProject/model')\n","\n","image_folder = '../data/labeled'\n","annotation_csv = '../data/annotation.csv'\n","object_detection_model_path = '../model/object_detection_resnet18.pth'\n","\n","cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n","print(device)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F_VGB7VG_1lG","colab_type":"code","colab":{}},"source":["def get_transform(): \n","    return torchvision.transforms.ToTensor()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GemGUTpF_1lK","colab_type":"code","colab":{}},"source":["labeled_scene_index = np.arange(107, 108)\n","labeled_trainset = LabeledDataset(\n","    image_folder=image_folder,\n","    annotation_file=annotation_csv,\n","    scene_index=labeled_scene_index,\n","    transform=get_transform(),\n","    extra_info=False\n","    )\n","dataloader = torch.utils.data.DataLoader(\n","    labeled_trainset,\n","    batch_size=1,\n","    shuffle=False,\n","    num_workers=4\n","    )\n","trainloader = torch.utils.data.DataLoader(labeled_trainset,\n","                                          batch_size=2,\n","                                          shuffle=True,\n","                                          num_workers=2,\n","                                          collate_fn=collate_fn)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0JM3IfC5A5SO","colab_type":"text"},"source":["## model_loader.py\n","\n","### For Object Detection"]},{"cell_type":"code","metadata":{"id":"4alVpEoXAuYT","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","import math\n","import time\n","\n","import utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Umf-_T5yAubX","colab_type":"code","colab":{}},"source":["def get_transform(): \n","    return torchvision.transforms.ToTensor()\n","\n","\n","def extract_features(one_sample):\n","    feature_extractor = torchvision.models.resnet18(pretrained=False)\n","    feature_extractor = nn.Sequential(*list(feature_extractor.children())[:-2])\n","    feature_extractor.cuda()\n","    return feature_extractor(one_sample)\n","\n","def concat_features(features, dim = 2):\n","    #dim 0 ==> stacking the images in the channel dimension\n","    #dim 1 ==> stacking the images in row dimension\n","    #dim 2 ==> stacking the images in column dimension\n","    tensor_tuples = torch.unbind(features, dim=0)\n","    concatenated_fm = torch.cat(tensor_tuples, dim=dim)\n","    return concatenated_fm \n","\n","def prepare_inputs(samples):\n","    \"\"\"\n","    Input: samples is a cuda tensor with size [batch_size, 6, 3, 256, 306]\n","    Output: a list of batch_size tensor, each tensor with size [512, 16, 114]\n","    \"\"\"\n","    batchsize = samples.shape[0]\n","    fe_batch = []\n","    for i in range(batchsize):\n","        image_tensor = samples[i]\n","        features = extract_features(image_tensor)\n","        #print(features.shape)\n","        features = concat_features(features)\n","        features = features.view(3, 512, 160)\n","        #print(features.shape)\n","        fe_batch.append(features)\n","    \n","    return fe_batch\n","\n","# Need to convert this to \n","def reorder_coord(pred_bboxes):\n","    xmin, ymin, xmax, ymax = pred_bboxes.unbind(1)\n","    return torch.stack((xmax, xmax, xmin, xmin, ymax, ymin, ymax, ymin), dim=1).view(-1, 2, 4)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEyRIz-TBSIS","colab_type":"code","colab":{}},"source":["class ModelLoader():\n","    # Fill the information for your team\n","    team_name = 'team_name'\n","    round_number = 1\n","    team_member = []\n","    contact_email = '@nyu.edu'\n","\n","    def __init__(self, model_file='put_your_model_file_name_here'):\n","        \"\"\"\n","        model_file = {'get_bboxes_model': object_detection_model_path,\n","                      'get_binary_RM_model': None}\n","        \"\"\"\n","        self.bboxes_model_weights =  model_file['get_bboxes_model']\n","        self.bboxes_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","        self.bboxes_model = self.bboxes_model.to(device)\n","        #self.model_path = '/scratch/nhl256/dl_project/model/object_detection_resnet18_epoch2.pth'\n","        self.bboxes_model.load_state_dict(torch.load(self.bboxes_model_weights))\n","        self.bboxes_model.eval()\n","\n","    def get_bounding_boxes(self, samples):\n","        # samples is a cuda tensor with size [batch_size, 6, 3, 256, 306]\n","        # You need to return a tuple with size 'batch_size' and each element is a cuda tensor [N, 2, 4]\n","        # where N is the number of object\n","        inputs = prepare_inputs(samples)\n","        predictions = self.bboxes_model(inputs)\n","        res = []\n","        for i in range(len(predictions)):\n","            prediction = predictions[i]\n","            pred_bboxes = prediction['boxes']\n","            reorder_pred_bboxes = reorder_coord(pred_bboxes)\n","            res.append(reorder_pred_bboxes)\n","\n","        return res\n","\n","    def get_binary_road_map(self, samples):\n","        # samples is a cuda tensor with size [batch_size, 6, 3, 256, 306]\n","        # You need to return a cuda tensor with size [batch_size, 800, 800] \n","        \n","        return torch.rand(1, 800, 800) > 0.5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ynYnBoU0CYkR","colab_type":"text"},"source":["## Get Bounding Boxes Threat Score"]},{"cell_type":"code","metadata":{"id":"aaVjs8yVCkIs","colab_type":"code","colab":{}},"source":["model_file = {'get_bboxes_model': object_detection_model_path,\n","                      'get_binary_RM_model': None}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vtKkohQCbV0","colab_type":"code","colab":{}},"source":["model_loader = ModelLoader(model_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kgN9HAuCxd5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"9d52429a-4f82-4b52-e809-fcfea3ddd6d8","executionInfo":{"status":"ok","timestamp":1588031355578,"user_tz":240,"elapsed":234,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["print('number of samples in dataloader is {}'.format(dataloader.__len__()))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["number of samples in dataloader is 126\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O1NOjRZVCq_x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6cfd2222-d434-4a6f-cc91-c4e0d2c43a3d","executionInfo":{"status":"ok","timestamp":1588031557692,"user_tz":240,"elapsed":75447,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["total = 0\n","total_ats_bounding_boxes = 0\n","total_ts_road_map = 0\n","for i, data in enumerate(dataloader):\n","    total += 1\n","    sample, target, road_image = data\n","    sample = sample.cuda()\n","\n","    predicted_bounding_boxes = model_loader.get_bounding_boxes(sample)[0].cpu()\n","    \n","\n","    ats_bounding_boxes = compute_ats_bounding_boxes(predicted_bounding_boxes,\n","                                                    target['bounding_box'][0])\n","    print('Number of pred bboxes {}'.format(predicted_bounding_boxes.shape))\n","    print('ats_bounding_boxes {}'.format(ats_bounding_boxes))\n","\n","    total_ats_bounding_boxes += ats_bounding_boxes"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([69, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.010049150325357914\n","Number of pred bboxes torch.Size([59, 2, 4])\n","ats_bounding_boxes 0.011021647602319717\n","Number of pred bboxes torch.Size([69, 2, 4])\n","ats_bounding_boxes 0.009490863420069218\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.006736313924193382\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.004126581363379955\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.0040640574879944324\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.007450771518051624\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.004003399517387152\n","Number of pred bboxes torch.Size([60, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([73, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([58, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([64, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([58, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([64, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([60, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([64, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([69, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([71, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([59, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([71, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([69, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([60, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([73, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([72, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([71, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([71, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([75, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([60, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([58, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([74, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([75, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([76, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([72, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([60, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.006070998962968588\n","Number of pred bboxes torch.Size([72, 2, 4])\n","ats_bounding_boxes 0.005785305052995682\n","Number of pred bboxes torch.Size([73, 2, 4])\n","ats_bounding_boxes 0.0057180337607860565\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.006070998962968588\n","Number of pred bboxes torch.Size([72, 2, 4])\n","ats_bounding_boxes 0.0057180337607860565\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.006070998962968588\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([74, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([71, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([64, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([68, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([63, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([72, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([60, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([60, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([70, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([60, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([61, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([62, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([67, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([66, 2, 4])\n","ats_bounding_boxes 0.0\n","Number of pred bboxes torch.Size([65, 2, 4])\n","ats_bounding_boxes 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sRL1PZjrEvLY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b4d00e57-894e-4c47-c4b0-b1dbecbb6775","executionInfo":{"status":"ok","timestamp":1588031851172,"user_tz":240,"elapsed":454,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["total_ats_bounding_boxes"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0924)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"Yf8Y5Kt2EwiJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}