{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"objectDectionFastRCNN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LMpEF8ZDd-lt","colab_type":"code","outputId":"1ee99488-dc2c-45d7-e578-307131b2a989","executionInfo":{"status":"ok","timestamp":1587749941602,"user_tz":240,"elapsed":470,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bajsXbCUQL3Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":138},"outputId":"cf8b1fcb-c65a-4eda-ad9b-eaf66d642330","executionInfo":{"status":"ok","timestamp":1587749944566,"user_tz":240,"elapsed":1487,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["!ls /content/gdrive/My\\ Drive/dl20/final_project/FinalProject"],"execution_count":2,"outputs":[{"output_type":"stream","text":["'=1.4'\t\t  explore_the_data.ipynb   model_loader.py\n","'=2.0.8'\t  fastRCNN\t\t   objectDectionFastRCNN.ipynb\n"," coco_utils.py\t  gcolab_data_helper.py    __pycache__\n"," data\t\t  helper.py\t\t   README.md\n"," data_helper.py   __MACOSX\t\t   requirements.txt\n"," engine.py\t  Mask_RCNN\t\t   utils.py\n"," env\t\t  MaskRCNN.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6qAWv9YOfRAi","colab_type":"code","outputId":"e8337b34-a830-486f-9ca0-7293c8a5eaac","executionInfo":{"status":"ok","timestamp":1587749947879,"user_tz":240,"elapsed":2089,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":155}},"source":["import os\n","!ls \n","os.chdir('gdrive/My Drive/dl20/final_project/FinalProject')\n","\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["gdrive\tsample_data\n","'=1.4'\t\t  explore_the_data.ipynb   model_loader.py\n","'=2.0.8'\t  fastRCNN\t\t   objectDectionFastRCNN.ipynb\n"," coco_utils.py\t  gcolab_data_helper.py    __pycache__\n"," data\t\t  helper.py\t\t   README.md\n"," data_helper.py   __MACOSX\t\t   requirements.txt\n"," engine.py\t  Mask_RCNN\t\t   utils.py\n"," env\t\t  MaskRCNN.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6itBTR5yLyCk","colab_type":"code","outputId":"fed13d14-f088-4db5-8a75-5381fa3caf34","executionInfo":{"status":"ok","timestamp":1587749432649,"user_tz":240,"elapsed":1293,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["!ls 'data/labeled'"],"execution_count":11,"outputs":[{"output_type":"stream","text":["__MACOSX    scene_109  scene_114  scene_119  scene_124\tscene_129\n","sample_107  scene_110  scene_115  scene_120  scene_125\tscene_130\n","scene_106   scene_111  scene_116  scene_121  scene_126\tscene_131\n","scene_107   scene_112  scene_117  scene_122  scene_127\tscene_132\n","scene_108   scene_113  scene_118  scene_123  scene_128\tscene_133\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X9PMrKKreF3N","colab_type":"code","outputId":"7daa6757-1d1a-44ef-f8db-3844200592dc","executionInfo":{"status":"error","timestamp":1587749437462,"user_tz":240,"elapsed":1232,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":548}},"source":["import os\n","import sys\n","from PIL import Image\n","\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","matplotlib.rcParams['figure.figsize'] = [5, 5]\n","matplotlib.rcParams['figure.dpi'] = 200\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","from data_helper import *\n","from helper import collate_fn, draw_box\n","\n","from coco_utils import get_coco_api_from_dataset\n","import utils\n","\n","import math\n","import pickle\n","import time\n","import copy"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-8c877c1b5bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcoco_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/dl20/final_project/FinalProject/coco_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transforms'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"NgZ9D4Q5-our","colab_type":"code","colab":{}},"source":["\n","# !mkdir data/labeled\n","# !ls\n","#!unzip data/labeledSet.zip -d data/labeled"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23wjtm3ufX2t","colab_type":"text"},"source":["# Test an example code"]},{"cell_type":"code","metadata":{"id":"Z-mow3YMfT-_","colab_type":"code","colab":{}},"source":["# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","# images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)\n","# labels = torch.randint(1, 91, (4, 11))\n","# images = list(image for image in images)\n","# targets = []\n","# for i in range(len(images)):\n","#     d = {}\n","#     d['boxes'] = boxes[i]\n","#     d['labels'] = labels[i]\n","#     targets.append(d)\n","# output = model(images, targets)\n","#output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A16_Anied-mJ","colab_type":"code","outputId":"93200542-1dee-4080-84e3-94cdeada709d","executionInfo":{"status":"ok","timestamp":1587748816905,"user_tz":240,"elapsed":251,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# All the images are saved in image_folder\n","# All the labels are saved in the annotation_csv file\n","\n","# image_folder = '../data'\n","# annotation_csv = '../data/annotation.csv'\n","\n","sys.path.append('gdrive/My Drive/dl20/final_project/FinalProject/data/labeled')\n","image_folder = 'data/labeled'\n","annotation_csv = 'data/annotation.csv'\n","\n","\n","cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n","print(device)\n","\n","# image_folder = '/Users/nhungle/Downloads/dl20_data'\n","# annotation_csv = '/Users/nhungle/Downloads/dl20_data/annotation.csv'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ri_jT4rHM6rb","colab_type":"code","outputId":"3db2587a-9933-44ce-846f-1ca4559442ae","executionInfo":{"status":"ok","timestamp":1587748833605,"user_tz":240,"elapsed":1360,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["!ls 'data/labeled'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__MACOSX    scene_109  scene_114  scene_119  scene_124\tscene_129\n","sample_107  scene_110  scene_115  scene_120  scene_125\tscene_130\n","scene_106   scene_111  scene_116  scene_121  scene_126\tscene_131\n","scene_107   scene_112  scene_117  scene_122  scene_127\tscene_132\n","scene_108   scene_113  scene_118  scene_123  scene_128\tscene_133\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n-PzB4lPd-n7","colab_type":"text"},"source":["# Labeled dataset"]},{"cell_type":"code","metadata":{"id":"Mk75N39Cd-n8","colab_type":"code","colab":{}},"source":["def inspect_target(index, labeled_scene_index):\n","    NUM_SAMPLE_PER_SCENE = 126\n","    NUM_IMAGE_PER_SAMPLE = 6\n","    image_names = [\n","        'CAM_FRONT_LEFT.jpeg',\n","        'CAM_FRONT.jpeg',\n","        'CAM_FRONT_RIGHT.jpeg',\n","        'CAM_BACK_LEFT.jpeg',\n","        'CAM_BACK.jpeg',\n","        'CAM_BACK_RIGHT.jpeg',\n","        ]\n","    scene_index = labeled_scene_index \n","    scene_id = scene_index[index // NUM_SAMPLE_PER_SCENE]\n","    sample_id = index % NUM_SAMPLE_PER_SCENE\n","    sample_path = os.path.join(image_folder, f'scene_{scene_id}', f'sample_{sample_id}') \n","    images = []\n","    for image_name in image_names:\n","        image_path = os.path.join(sample_path, image_name)\n","        image = Image.open(image_path)\n","        images.append(transform(image))\n","    image_tensor = torch.stack(images)\n","    annotation_file = annotation_csv \n","    annotation_dataframe = pd.read_csv(annotation_file)\n","    data_entries = annotation_dataframe[(annotation_dataframe['scene'] == scene_id) & (annotation_dataframe['sample'] == sample_id)]\n","    corners = data_entries[['fl_x', 'fr_x', 'bl_x', 'br_x', 'fl_y', 'fr_y','bl_y', 'br_y']].to_numpy()\n","    categories = data_entries.category_id.to_numpy()\n","    num_objects = len(categories)\n","    boxes = []\n","    for i in range(num_objects):\n","        xmin = min(corners[i][:4])\n","        xmax = max(corners[i][:4])\n","        ymin = min(corners[i][4:])\n","        ymax = max(corners[i][4:])\n","        boxes.append([xmin, ymin, xmax, ymax])\n","    return data_entries, image_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fom2g6MJd-oP","colab_type":"code","colab":{}},"source":["train_labeled_scene_index = np.arange(131, 132)\n","test_labeled_scene_index = np.arange(132, 133)\n","\n","transform = torchvision.transforms.ToTensor()\n","fasterRCNN_trainset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=train_labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","train_loader = torch.utils.data.DataLoader(fasterRCNN_trainset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)\n","fasterRCNN_testset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=test_labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","test_loader = torch.utils.data.DataLoader(fasterRCNN_testset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3YwehE6M0UC","colab_type":"code","outputId":"16cc4b4e-cb40-47e8-9059-a34b7eba4f20","executionInfo":{"status":"ok","timestamp":1587748843023,"user_tz":240,"elapsed":1872,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["! ls image_folder"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ls: cannot access 'image_folder': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WiSVjZYzMW15","colab_type":"code","outputId":"4e917f8f-4588-4255-ab18-5db0cb775c7a","executionInfo":{"status":"ok","timestamp":1587748845417,"user_tz":240,"elapsed":1432,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["! ls 'data/labeled/scene_131/sample_26'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CAM_BACK.jpeg\t    CAM_BACK_RIGHT.jpeg  CAM_FRONT_LEFT.jpeg   ego.png\n","CAM_BACK_LEFT.jpeg  CAM_FRONT.jpeg\t CAM_FRONT_RIGHT.jpeg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7HFKc2hcbN3e","colab_type":"code","colab":{}},"source":["train_loader.__len__()\n","sample, targets = iter(train_loader).next()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bpy2gf9mNk8h","colab_type":"code","outputId":"9c588be8-ab52-48b4-defd-fa23fe2b82d1","executionInfo":{"status":"ok","timestamp":1587748954425,"user_tz":240,"elapsed":370,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["index = targets[0]['image_id'].item()\n","data_entries, idx_tensor = inspect_target(index, train_labeled_scene_index)\n","data_entries[\"category_id\"].values == targets[0]['labels'].data.numpy()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"pq87_1TsZdxH","colab_type":"text"},"source":["## Prepare inputs for the model"]},{"cell_type":"code","metadata":{"id":"C3v00HG3ZdJP","colab_type":"code","colab":{}},"source":["def extract_features(one_sample):\n","    feature_extractor = torchvision.models.resnet18(pretrained=False)\n","    feature_extractor = nn.Sequential(*list(feature_extractor.children())[:-2])\n","    #feature_extractor.to(device)\n","    # for param in feature_extractor.parameters():\n","    #     param.requires_grad = True\n","    return feature_extractor(one_sample)\n","\n","\n","def concat_features(features, dim = 2):\n","    #dim 0 ==> stacking the images in the channel dimension\n","    #dim 1 ==> stacking the images in row dimension\n","    #dim 2 ==> stacking the images in column dimension\n","    tensor_tuples = torch.unbind(features, dim=0)\n","    concatenated_fm = torch.cat(tensor_tuples, dim=dim)\n","    return concatenated_fm \n","\n","def prepare_inputs(sample):\n","    \"\"\"\n","    Input: samples is a cuda tensor with size [batch_size, 6, 3, 256, 306]\n","    Output: a list of batch_size tensor, each tensor with size [512, 16, 114]\n","    \"\"\"\n","    batchsize = sample.shape[0]\n","    fe_batch = []\n","    for i in range(batchsize):\n","        image_tensor = sample[i]\n","        features = extract_features(image_tensor)\n","        #print(features.shape)\n","        features = concat_features(features)\n","        features = features.view(3, 512, 160)\n","        #print(features.shape)\n","        fe_batch.append(features)\n","    \n","    return fe_batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuAHlunjZlLB","colab_type":"code","colab":{}},"source":["# sample = torch.stack(sample)\n","# images = prepare_inputs(sample)\n","# images = list(image.to(device) for image in images)\n","# targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrbXoiO4RGse","colab_type":"text"},"source":["## Test pretrained model on my input"]},{"cell_type":"code","metadata":{"id":"LRNs29FNRGB_","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r551MU-nd-qk","colab_type":"code","colab":{}},"source":["output1 = model(images, targets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0Hxh3tYazHV","colab_type":"code","outputId":"aca552aa-3a2d-4202-9e0e-9cb7a61fd0c9","executionInfo":{"status":"ok","timestamp":1587653233103,"user_tz":240,"elapsed":922,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["output1"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'loss_box_reg': tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>),\n"," 'loss_classifier': tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward>),\n"," 'loss_objectness': tensor(1.8566, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n"," 'loss_rpn_box_reg': tensor(0.6337, device='cuda:0', grad_fn=<DivBackward0>)}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"eY5lf6lfbZTU","colab_type":"text"},"source":["## Train for 1 sence"]},{"cell_type":"code","metadata":{"id":"k2p5G8s6cRBv","colab_type":"code","colab":{}},"source":["# Refer to: https://github.com/pytorch/vision/blob/master/references/detection/engine.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RCAioWzd_RC","colab_type":"code","colab":{}},"source":["train_labeled_scene_index = np.arange(131, 132)\n","test_labeled_scene_index = np.arange(132, 133)\n","fasterRCNN_trainset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=train_labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","train_loader = torch.utils.data.DataLoader(fasterRCNN_trainset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)\n","fasterRCNN_testset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=test_labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","test_loader = torch.utils.data.DataLoader(fasterRCNN_testset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEsCSbEEdsgC","colab_type":"code","outputId":"cb093db4-2bf6-4b3b-8de8-31e9fcce626a","executionInfo":{"status":"error","timestamp":1587749031431,"user_tz":240,"elapsed":432,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"source":[""],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-6a211f242ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcoco_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/dl20/final_project/FinalProject/coco_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transforms'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"u0mfqyfzbYgy","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                            momentum=0.9, weight_decay=0.0005)\n","# and a learning rate scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                step_size=3,\n","                                                gamma=0.1)\n","\n","# let's train it for 10 epochs\n","num_epochs = 1\n","epoch = 0\n","print_freq = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7REJR4wZiZEv","colab_type":"code","colab":{}},"source":["def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n","    model.train()\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n","    header = 'Epoch: [{}]'.format(epoch)\n","\n","    lr_scheduler = None\n","    if epoch == 0:\n","        warmup_factor = 1. / 1000\n","        warmup_iters = min(1000, len(data_loader) - 1)\n","\n","        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n","\n","    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n","        images = torch.stack(images)\n","        #print(images.shape)\n","        images = prepare_inputs(images)\n","        #print(images[0].shape)\n","\n","        images = list(image.to(device) for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        #print(loss_dict)\n","\n","        losses = sum(loss for loss in loss_dict.values())\n","        #print(losses)\n","\n","        # reduce losses over all GPUs for logging purposes\n","        loss_dict_reduced = utils.reduce_dict(loss_dict)\n","        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n","\n","        loss_value = losses_reduced.item()\n","\n","        if not math.isfinite(loss_value):\n","            print(\"Loss is {}, stopping training\".format(loss_value))\n","            print(loss_dict_reduced)\n","            sys.exit(1)\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","\n","        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n","\n","    return losses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNgNdjDyimY4","colab_type":"code","outputId":"26afdfde-025b-451f-a17e-6a3bbadbd308","executionInfo":{"status":"error","timestamp":1587745472535,"user_tz":240,"elapsed":4077,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":483}},"source":["train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-f23dba7cb662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-7bc1e6be6ee4>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_lr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/dl20/final_project/FinalProject/utils.py\u001b[0m in \u001b[0;36mlog_every\u001b[0;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[1;32m    207\u001b[0m             ])\n\u001b[1;32m    208\u001b[0m         \u001b[0mMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/gdrive/My Drive/dl20/final_project/FinalProject/data_helper.py\", line 176, in __getitem__\n    image = Image.open(image_path)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2809, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'data/scene_131/sample_55/CAM_FRONT_LEFT.jpeg'\n"]}]},{"cell_type":"markdown","metadata":{"id":"bKLzAqS5jayO","colab_type":"text"},"source":["## Evaluate"]},{"cell_type":"code","metadata":{"id":"6N7S-1srTbRg","colab_type":"code","colab":{}},"source":["def prepare_pred_results(predictions):\n","    pred_boxes = []\n","    pred_labels = []\n","    pred_scores = []\n","    for prediction in predictions:\n","        #print(prediction)\n","        if len(prediction) == 0:\n","            continue\n","        boxes = prediction[\"boxes\"]\n","        boxes = reorder_coord(boxes).tolist()\n","        scores = prediction[\"scores\"].tolist()\n","        labels = prediction[\"labels\"].tolist()\n","\n","        pred_boxes.append(boxes)\n","        pred_labels.append(labels)\n","        pred_scores.append(scores)\n","\n","    return pred_boxes, pred_labels, pred_scores\n","\n","def reorder_coord(boxes):\n","    xmin, ymin, xmax, ymax = boxes.unbind(1)\n","    return torch.stack((ymin, xmin, ymax, xmax), dim=1)\n","\n","def prepare_gt(targets):\n","    gt_boxes = []\n","    gt_labels = []\n","    for target in targets:\n","        boxes = target['boxes']\n","        boxes = reorder_coord(boxes).tolist()\n","        labels = target[\"labels\"].tolist()\n","        gt_boxes.append(boxes)\n","        gt_labels.append(labels)\n","    return gt_boxes, gt_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2a_EldORlxqm","colab_type":"code","colab":{}},"source":["# Make sure that bbox_a, bbox_b = np.array\n","\n","def bbox_iou(bbox_a, bbox_b):\n","    #print(type(bbox_a), type(bbox_b))\n","    bbox_a = np.array(bbox_a)\n","    bbox_b = np.array(bbox_b)\n","\n","    # print(type(bbox_a), type(bbox_b))\n","    # print(bbox_a.shape, bbox_b.shape)\n","    if bbox_a.shape[1] != 4 or bbox_b.shape[1] != 4:\n","        raise IndexError\n","\n","    # top left (i.e., ymin, xmin)\n","    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n","    # bottom right (i.e., ymax, xmax)\n","    br = np.minimum(bbox_a[:, None, 2:], bbox_b[:, 2:])\n","\n","    # Area of intersection: (tl < br) = bool, (br-tl) = (ymax-ymin) \n","    area_i = np.prod(br - tl, axis=2) * (tl < br).all(axis=2)\n","    area_a = np.prod(bbox_a[:, 2:] - bbox_a[:, :2], axis=1)\n","    area_b = np.prod(bbox_b[:, 2:] - bbox_b[:, :2], axis=1)\n","\n","    return area_i / (area_a[:, None] + area_b - area_i)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahoOrX-8ZFzT","colab_type":"code","colab":{}},"source":["def cal_TP_FP_iou(pred_bbox_c, gt_bbox_c, iou_thres=0.5):\n","    iou_table = bbox_iou(pred_bbox_c, gt_bbox_c)\n","    num_pred_bboxes = iou_table.shape[0]\n","    num_gt_bboxes = iou_table.shape[1]\n","    TP = np.zeros(num_pred_bboxes)\n","    FP = np.zeros(num_pred_bboxes)\n","    # For each pred_bounding box:\n","      # Find the most relevant gt_bbox (i.e., the gt_bbox with max IoU)\n","      # If IoU < threshold, then flag it as FP\n","      # If IoU >= threshold, then:\n","        # If that gt_bbox already has already matched with another pred_bbox:\n","          # Flag it as FP\n","        # Else:\n","          # Flag it as TP\n","\n","    # TP only happens if the pred_bbox mathes with a gt_bbox\n","    for i in range(num_pred_bboxes):\n","        gt_bbox_index = np.argmax(iou_table[i])\n","        best_pred_bbox_index_for_selected_gt_bbox = np.argmax(iou_table[:,gt_bbox_index])\n","        if iou_table[i, gt_bbox_index] > iou_thres \\\n","            and gt_bbox_index == best_pred_bbox_index_for_selected_gt_bbox:\n","            TP[i] = 1\n","        else:\n","            FP[i] = 1\n","\n","    TP_cum = np.sum(TP)\n","    FP_cum = np.sum(FP)\n","\n","    if (TP_cum + FP_cum) != num_pred_bboxes:\n","        print(\"WRONG CALCULATION OF FP\")\n","    return TP_cum, FP_cum"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bzx15kDKS3Zt","colab_type":"code","colab":{}},"source":["# Test for cal_TP_FP_iou\n","\n","def inspect_call_TP_FP_iou(test_images, test_targets):\n","    test_images = torch.stack(test_images)\n","    #print(test_images.shape)\n","    test_images = prepare_inputs(test_images)\n","    #print(test_images[0].shape)\n","\n","    test_images = list(image.to(device) for image in test_images)\n","    test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","    model.eval()\n","    predictions = model(test_images)\n","\n","    pred_bboxes, pred_labels, pred_scores = prepare_pred_results(predictions)\n","    gt_bboxes, gt_labels = prepare_gt(test_targets)\n","\n","    for pred_bbox, pred_label, pred_score, gt_bbox, gt_label in \\\n","        zip(pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels):\n","        pred_bbox = np.array(pred_bbox)\n","        pred_score = np.array(pred_score)\n","        pred_label = np.array(pred_label)\n","        gt_bbox = np.array(gt_bbox)\n","        gt_label = np.array(gt_label)\n","        unique_share_classes = (np.unique(np.concatenate((pred_label, gt_label))))\n","        \n","        for c in unique_share_classes:\n","            pred_class_c_index = np.where(pred_label == c)[0]\n","            pred_bbox_c = pred_bbox[pred_class_c_index]\n","            gt_class_c_index = np.where(gt_label == c)[0]\n","            #print(gt_class_c_index)\n","            gt_bbox_c = gt_bbox[gt_class_c_index]\n","            num_gt_bboxes = len(gt_class_c_index)\n","            num_pred_bboxes = len(pred_class_c_index)\n","            print('class {} with {} gt_bboxes and {} pred_bboxes'.format(c, num_gt_bboxes, num_pred_bboxes))\n","            # print(num_gt_bboxes)\n","            # print(num_pred_bboxes)\n","            if num_pred_bboxes == 0:\n","                class_TP = 0\n","                class_FP = 0\n","                class_FN = num_gt_bboxes\n","            elif num_gt_bboxes == 0:\n","                class_TP = 0\n","                class_FP = num_pred_bboxes\n","                class_FN = 0\n","            else:\n","                class_TP, class_FP = cal_TP_FP_iou(pred_bbox_c, gt_bbox_c, iou_thres)\n","                class_FN = num_gt_bboxes - class_TP\n","                print(class_TP + class_FP == num_pred_bboxes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8N2DCbcJe92u","colab_type":"code","colab":{}},"source":["# for i in range(3):\n","#     print('Iter {}'.format(i))\n","#     test_images, test_targets = next(iter(test_loader))\n","#     inspect_call_TP_FP_iou(test_images, test_targets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"honU3_7QQLwr","colab_type":"code","colab":{}},"source":["def evaluate_one_batch(predictions, test_targets, res, iou_thres=0.5):\n","\n","    pred_bboxes, pred_labels, pred_scores = prepare_pred_results(predictions)\n","    gt_bboxes, gt_labels = prepare_gt(test_targets)\n","    # res stores the TP_FP dict for each class\n","    # Each TP_FP dict stores the TP_FP for each class \n","    \n","    batch_total_TP = 0\n","    batch_total_FP = 0\n","    batch_total_FN = 0\n","    batch_total_num_object = 0\n","    batch_res = {c: {'TP':0, 'FP': 0, 'FN': 0} for c in range(9)}\n","\n","    for pred_bbox, pred_label, pred_score, gt_bbox, gt_label in \\\n","        zip(pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels):\n","\n","        pred_bbox = np.array(pred_bbox)\n","        pred_score = np.array(pred_score)\n","        pred_label = np.array(pred_label)\n","        gt_bbox = np.array(gt_bbox)\n","        gt_label = np.array(gt_label)\n","        unique_share_classes = (np.unique(np.concatenate((pred_label, gt_label))))\n","        \n","        for c in unique_share_classes:\n","            pred_class_c_index = np.where(pred_label == c)[0]\n","            pred_bbox_c = pred_bbox[pred_class_c_index]\n","            gt_class_c_index = np.where(gt_label == c)[0]\n","            #print(gt_class_c_index)\n","            gt_bbox_c = gt_bbox[gt_class_c_index]\n","            num_gt_bboxes = len(gt_class_c_index)\n","            num_pred_bboxes = len(pred_class_c_index)\n","            #print('class {} with {} gt_bboxes and {} pred_bboxes'.format(c, num_gt_bboxes, num_pred_bboxes))\n","            if num_pred_bboxes == 0:\n","                class_TP = 0\n","                class_FP = 0\n","                class_FN = num_gt_bboxes\n","            elif num_gt_bboxes == 0:\n","                class_TP = 0\n","                class_FP = num_pred_bboxes\n","                class_FN = 0\n","            else:\n","                class_TP, class_FP = cal_TP_FP_iou(pred_bbox_c, gt_bbox_c, iou_thres)\n","                class_FN = num_gt_bboxes - class_TP\n","                #print(class_TP + class_FP == num_pred_bboxes)\n","\n","            batch_total_TP += class_TP\n","            batch_total_FP += class_FP\n","            batch_total_FN += class_FN\n","            batch_total_num_object += num_gt_bboxes\n","\n","            batch_res[c]['TP'] += class_TP\n","            batch_res[c]['FP'] += class_FP\n","            batch_res[c]['FN'] += class_FN\n","\n","            res[c]['TP'] += class_TP\n","            res[c]['FP'] += class_FP\n","            res[c]['FN'] += class_FN\n","            \n","    return res, batch_res, batch_total_TP, batch_total_FP, batch_total_FN, batch_total_num_object"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nji9KKjySsLT","colab_type":"code","colab":{}},"source":["# Inspect evaluate_one_batch\n","def inspect_evaluate_one_batch(test_images, test_targets, final_res):\n","    test_images = torch.stack(test_images)\n","    #print(test_images.shape)\n","    test_images = prepare_inputs(test_images)\n","    #print(test_images[0].shape)\n","\n","    test_images = list(image.to(device) for image in test_images)\n","    test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","    model.eval()\n","    predictions = model(test_images)\n","\n","    final_res, batch_res, batch_total_TP, batch_total_FP, batch_total_FN, batch_total_num_object \\\n","    = evaluate_one_batch(predictions, test_targets, final_res, iou_thres=0.5)\n","\n","    return final_res, batch_res, batch_total_TP, batch_total_FP, batch_total_FN, batch_total_num_object"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfzs9R0nS5Wr","colab_type":"code","outputId":"bf329a68-8d6e-4aac-9662-391a10a96fa8","executionInfo":{"status":"ok","timestamp":1587738755570,"user_tz":240,"elapsed":9747,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":175}},"source":["\n","final_res = {c: {'TP':0, 'FP': 0, 'FN': 0} for c in range(9)}\n","final_TP = 0\n","final_FP = 0\n","final_FN = 0\n","final_num_objects = 0\n","\n","# test for 2 batches\n","for i in range(2):\n","    test_images, test_targets = next(iter(test_loader))\n","    final_res, batch_res, batch_total_TP, batch_total_FP, batch_total_FN, batch_total_num_object \\\n","    = inspect_evaluate_one_batch(test_images, test_targets, final_res)\n","\n","    print('batch {}'.format(i))\n","\n","    \n","    print(batch_total_TP, batch_total_FN, batch_total_num_object)\n","    print('cur batch res:', batch_res)\n","    print('final res after this batch:', final_res)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["batch 0\n","0 20 20\n","cur batch res: {0: {'TP': 0, 'FP': 0, 'FN': 1}, 1: {'TP': 0, 'FP': 0, 'FN': 0}, 2: {'TP': 0, 'FP': 0, 'FN': 16}, 3: {'TP': 0, 'FP': 0, 'FN': 2}, 4: {'TP': 0, 'FP': 0, 'FN': 1}, 5: {'TP': 0, 'FP': 0, 'FN': 0}, 6: {'TP': 0, 'FP': 0, 'FN': 0}, 7: {'TP': 0, 'FP': 0, 'FN': 0}, 8: {'TP': 0, 'FP': 0, 'FN': 0}}\n","final res after this batch: {0: {'TP': 0, 'FP': 0, 'FN': 1}, 1: {'TP': 0, 'FP': 0, 'FN': 0}, 2: {'TP': 0, 'FP': 0, 'FN': 16}, 3: {'TP': 0, 'FP': 0, 'FN': 2}, 4: {'TP': 0, 'FP': 0, 'FN': 1}, 5: {'TP': 0, 'FP': 0, 'FN': 0}, 6: {'TP': 0, 'FP': 0, 'FN': 0}, 7: {'TP': 0, 'FP': 0, 'FN': 0}, 8: {'TP': 0, 'FP': 0, 'FN': 0}}\n","batch 1\n","0 20 20\n","cur batch res: {0: {'TP': 0, 'FP': 0, 'FN': 1}, 1: {'TP': 0, 'FP': 0, 'FN': 0}, 2: {'TP': 0, 'FP': 0, 'FN': 19}, 3: {'TP': 0, 'FP': 0, 'FN': 0}, 4: {'TP': 0, 'FP': 0, 'FN': 0}, 5: {'TP': 0, 'FP': 0, 'FN': 0}, 6: {'TP': 0, 'FP': 0, 'FN': 0}, 7: {'TP': 0, 'FP': 0, 'FN': 0}, 8: {'TP': 0, 'FP': 0, 'FN': 0}}\n","final res after this batch: {0: {'TP': 0, 'FP': 0, 'FN': 2}, 1: {'TP': 0, 'FP': 0, 'FN': 0}, 2: {'TP': 0, 'FP': 0, 'FN': 35}, 3: {'TP': 0, 'FP': 0, 'FN': 2}, 4: {'TP': 0, 'FP': 0, 'FN': 1}, 5: {'TP': 0, 'FP': 0, 'FN': 0}, 6: {'TP': 0, 'FP': 0, 'FN': 0}, 7: {'TP': 0, 'FP': 0, 'FN': 0}, 8: {'TP': 0, 'FP': 0, 'FN': 0}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hhl7niyU3psc","colab_type":"code","outputId":"72b343a3-6a3d-4d84-ad9e-69ff3da2cc58","executionInfo":{"status":"ok","timestamp":1587677127103,"user_tz":240,"elapsed":379,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["31"]},"metadata":{"tags":[]},"execution_count":369}]},{"cell_type":"code","metadata":{"id":"5Hf3Cii6S5gf","colab_type":"code","colab":{}},"source":["def evaluate_one_epoch(test_loader, iou_thres=0.5):\n","    # Evaluate. for all data point in the evaluaton set\n","    final_res = {c: {'TP':0, 'FP': 0, 'FN': 0} for c in range(9)}\n","    final_TP = 0\n","    final_FP = 0\n","    final_FN = 0\n","    final_num_objects = 0\n","\n","    for iter_, (test_images, test_targets) in enumerate(test_loader):\n","        # if iter_ % 50 == 0:\n","        #     print('iter', iter_)\n","        #print('iter', iter_)\n","        test_images = torch.stack(test_images)\n","        #print(test_images.shape)\n","        test_images = prepare_inputs(test_images)\n","        #print(test_images[0].shape)\n","\n","        test_images = list(image.to(device) for image in test_images)\n","        test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","        model.eval()\n","        predictions = model(test_images)\n","\n","        # Evaluate for one batch\n","        final_res, batch_res, batch_total_TP, batch_total_FP, batch_total_FN, batch_total_num_object \\\n","                    = evaluate_one_batch(predictions, test_targets, final_res, iou_thres=0.5)\n","\n","        \n","        final_TP += batch_total_TP\n","        final_FP += batch_total_FP\n","        final_FN += batch_total_FN\n","        final_num_objects += batch_total_num_object\n","\n","    return final_res, final_TP, final_FP, final_FN, final_num_objects"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zop8Z75IS5ep","colab_type":"code","outputId":"ed65157d-23c8-4f3f-8a91-00a27a6ee63d","executionInfo":{"status":"ok","timestamp":1587739135153,"user_tz":240,"elapsed":95168,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["final_res, final_TP, final_FP, final_FN, final_num_objects = evaluate_one_epoch(test_loader, iou_thres=0.5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["iter 0\n","iter 50\n","iter 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JFT09TgzS5cW","colab_type":"code","colab":{}},"source":["def evaluate_threst_score(TP, FP, FN):\n","    return (TP / (TP + FP + FN))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEx2ls44dlXz","colab_type":"code","outputId":"b2b39517-2567-4a24-f515-9114823598e4","executionInfo":{"status":"ok","timestamp":1587739141694,"user_tz":240,"elapsed":278,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["evaluate_threst_score(final_TP, final_FP, final_FN)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"ejRrnjTloLBc","colab_type":"code","outputId":"4c05fac2-7eb0-450a-b874-855a51e1b4e9","executionInfo":{"status":"ok","timestamp":1587739147790,"user_tz":240,"elapsed":275,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["final_res"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: {'FN': 158, 'FP': 0, 'TP': 0},\n"," 1: {'FN': 0, 'FP': 0, 'TP': 0},\n"," 2: {'FN': 3074, 'FP': 0, 'TP': 0},\n"," 3: {'FN': 390, 'FP': 0, 'TP': 0},\n"," 4: {'FN': 27, 'FP': 0, 'TP': 0},\n"," 5: {'FN': 0, 'FP': 0, 'TP': 0},\n"," 6: {'FN': 20, 'FP': 0, 'TP': 0},\n"," 7: {'FN': 0, 'FP': 0, 'TP': 0},\n"," 8: {'FN': 0, 'FP': 0, 'TP': 0}}"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"markdown","metadata":{"id":"ve5Zlqi-dvxf","colab_type":"text"},"source":["## Train and Evaluate for Multiple Epochs"]},{"cell_type":"code","metadata":{"id":"mm_4-JrdeH59","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.Adam(params, lr=0.0001)\n","# optimizer = torch.optim.SGD(params, lr=0.005,\n","#                             momentum=0.9, weight_decay=0.0005)\n","# and a learning rate scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                step_size=3,\n","                                                gamma=0.1)\n","\n","# let's train it for 10 epochs\n","num_epochs = 10\n","epoch = 0\n","print_freq = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4fAgXgidudg","colab_type":"code","colab":{}},"source":["def train_eval(model, train_loader, test_loader, iou_thres=0.5, num_epochs=10):\n","    train_losses = []\n","    eval_threatscores = []\n","    eval_final_res = []\n","    best_eval_ts = 0\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    for epoch in range(num_epochs):\n","        loss = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq)\n","        train_losses.append(loss)\n","        \n","        final_res, final_TP, final_FP, final_FN, final_num_objects = evaluate_one_epoch(test_loader, iou_thres=0.5)\n","\n","        print(\"epoch: {}\".format(epoch))\n","        print(final_TP, final_FP, final_FN, final_num_objects)\n","        eval_final_res.append(final_res)\n","        eval_ts = evaluate_threst_score(final_TP, final_FP, final_FN)\n","        eval_threatscores.append(eval_ts)\n","        if epoch % 2 == 0:\n","            print(\"epoch: {} eval_ts {}\".format(epoch, eval_ts))\n","\n","        if eval_ts > best_eval_ts:\n","            best_eval_ts = eval_ts \n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    return model, best_model_wts, train_losses, eval_final_res"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OsAuhVThduhA","colab_type":"code","outputId":"48469848-d9f1-49f9-a91a-4fb9780fad72","executionInfo":{"status":"error","timestamp":1587740890014,"user_tz":240,"elapsed":837,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":517}},"source":["model, best_model_wts, train_losses, eval_final_res = train_eval(model, train_loader,\n","                                                                 test_loader, iou_thres=0.5,\n","                                                                 num_epochs=10)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-99-46553654950a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model, best_model_wts, train_losses, eval_final_res = train_eval(model, train_loader,\n\u001b[1;32m      2\u001b[0m                                                                  \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_thres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                                                  num_epochs=10)\n\u001b[0m","\u001b[0;32m<ipython-input-98-9e76baf298cc>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(model, train_loader, test_loader, iou_thres, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbest_model_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-87-7bc1e6be6ee4>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_lr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/dl20/final_project/FinalProject/utils.py\u001b[0m in \u001b[0;36mlog_every\u001b[0;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[1;32m    207\u001b[0m             ])\n\u001b[1;32m    208\u001b[0m         \u001b[0mMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/gdrive/My Drive/dl20/final_project/FinalProject/data_helper.py\", line 176, in __getitem__\n    image = Image.open(image_path)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2809, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'data/scene_109/sample_5/CAM_FRONT_LEFT.jpeg'\n"]}]},{"cell_type":"code","metadata":{"id":"Naw6li0b09RY","colab_type":"code","outputId":"70a1d53f-67ed-4e70-b5ad-3f8377c580ca","executionInfo":{"status":"ok","timestamp":1587740004966,"user_tz":240,"elapsed":415,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":328}},"source":["eval_final_res"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3073.0, 'FP': 12599.0, 'TP': 1.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}},\n"," {0: {'FN': 158, 'FP': 0, 'TP': 0},\n","  1: {'FN': 0, 'FP': 0, 'TP': 0},\n","  2: {'FN': 3070.0, 'FP': 846.0, 'TP': 4.0},\n","  3: {'FN': 390, 'FP': 0, 'TP': 0},\n","  4: {'FN': 27, 'FP': 0, 'TP': 0},\n","  5: {'FN': 0, 'FP': 0, 'TP': 0},\n","  6: {'FN': 20, 'FP': 0, 'TP': 0},\n","  7: {'FN': 0, 'FP': 0, 'TP': 0},\n","  8: {'FN': 0, 'FP': 0, 'TP': 0}}]"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"DlPUDruY09M6","colab_type":"code","outputId":"fb88fa50-a1d1-4336-9802-ff5c60c3f325","executionInfo":{"status":"ok","timestamp":1587679121033,"user_tz":240,"elapsed":519,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["train_losses\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor(0.8429, device='cuda:0', grad_fn=<AddBackward0>),\n"," tensor(0.5462, device='cuda:0', grad_fn=<AddBackward0>),\n"," tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)]"]},"metadata":{"tags":[]},"execution_count":383}]},{"cell_type":"code","metadata":{"id":"pXmfiNDgJRY-","colab_type":"code","outputId":"aaeffc31-aa15-44d0-9d0a-61b203f837f1","executionInfo":{"status":"ok","timestamp":1587666212852,"user_tz":240,"elapsed":351,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["# res stores the TP_FP dict for each sample in the batch\n","# Each TP_FP dict stores the TP_FP for each class \n","res = []\n","batch_total_TP = 0\n","batch_total_FP = 0\n","batch_total_FN = 0\n","j = 0\n","for pred_bbox, pred_label, pred_score, gt_bbox, gt_label in \\\n","zip(pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels):\n","\n","    pred_bbox = np.array(pred_bbox)\n","    pred_score = np.array(pred_score)\n","    pred_label = np.array(pred_label)\n","    gt_bbox = np.array(gt_bbox)\n","    gt_label = np.array(gt_label)\n","    unique_share_classes = (np.unique(np.concatenate((pred_label, gt_label))))\n","    #print(unique_share_classes)\n","    TP_FP_class = {}\n","    for c in unique_share_classes:\n","        # Get all the predicted bounding boxes of class c\n","\n","        pred_class_c_index = np.where(pred_label == c)[0]\n","        pred_bbox_c = pred_bbox[pred_class_c_index]\n","        gt_class_c_index = np.where(gt_label == c)[0]\n","        #print(gt_class_c_index)\n","        gt_bbox_c = gt_bbox[gt_class_c_index]\n","        npos = len(gt_class_c_index)\n","        print('class {}'.format(c))\n","        print('num predicted bbox for this class {}'.format(len(pred_class_c_index)))\n","        print('num gt bbox for this class {}'.format(len(gt_class_c_index)))\n","\n","        iou_table = bbox_iou(pred_bbox_c, gt_bbox_c)\n","        num_pred_bboxes = iou_table.shape[0]\n","        num_gt_bboxes = iou_table.shape[1]\n","        TP = np.zeros(len(pred_class_c_index))\n","        FP = np.zeros(len(pred_class_c_index))\n","        # For each pred_bounding box:\n","          # Find the most relevant gt_bbox (i.e., the gt_bbox with max IoU)\n","          # If IoU < threshold, then flag it as FP\n","          # If IoU >= threshold, then:\n","            # If that gt_bbox already has already matched with another pred_bbox:\n","              # Flag it as FP\n","            # Else:\n","              # Flag it as TP\n","\n","        # TP only happens if the pred_bbox mathes with a gt_bbox\n","\n","        for i in range(len(pred_class_c_index)):\n","            gt_bbox_index = np.argmax(iou_table[i])\n","            best_pred_bbox_index_for_selected_gt_bbox = np.argmax(iou_table[:,gt_bbox_index])\n","            if iou_table[i, gt_bbox_index] > iou_thres \\\n","                and gt_bbox_index == best_pred_bbox_index_for_selected_gt_bbox:\n","                TP[i] = 1\n","            else:\n","                FP[i] = 1\n","        TP_cum = np.sum(TP)\n","        FP_cum = np.sum(FP)\n","        FN_cum = npos - TP_cum\n","\n","        batch_total_TP += TP_cum\n","        batch_total_FP += FP_cum\n","        batch_total_FN += FN_cum\n","        #print(c)\n","\n","        TP_FP_class[c] = [TP_cum, FP_cum, FN_cum]\n","\n","    res.append(TP_FP_class)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["class 0\n","num predicted bbox for this class 0\n","num gt bbox for this class 1\n","class 2\n","num predicted bbox for this class 4\n","num gt bbox for this class 27\n","class 3\n","num predicted bbox for this class 0\n","num gt bbox for this class 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bZCj9OMXrg6-","colab_type":"code","colab":{}},"source":["def evaluate_test_samples(model, test_images, test_targets):\n","  test_images = torch.stack(test_images)\n","  #print(test_images.shape)\n","  test_images = prepare_inputs(test_images)\n","  #print(test_images[0].shape)\n","\n","  test_images = list(image.to(device) for image in test_images)\n","  test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","  model.eval()\n","  predictions = model(test_images)\n","\n","  for i in range(len(predictions)):\n","      num_objects_predicted = len(predictions[i]['labels'])\n","      num_objects_gt = len(test_targets[i]['labels'])\n","      print('num object predicted: {}, num_object_ground_truth: {}'.format(num_objects_predicted, num_objects_gt))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i64fm2Ddye_H","colab_type":"code","outputId":"5ccacf57-22cd-4772-c071-f0793f6a10e8","executionInfo":{"status":"ok","timestamp":1587590986107,"user_tz":240,"elapsed":24130,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["for i in range(3):\n","    test_images, test_targets = next(iter(test_loader))\n","    evaluate_test_samples(model, test_images, test_targets)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["num object predicted: 58, num_object_ground_truth: 17\n","num object predicted: 38, num_object_ground_truth: 27\n","num object predicted: 28, num_object_ground_truth: 20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hXslpd4-d-rQ","colab_type":"text"},"source":["## Customize Fast RCNN"]},{"cell_type":"code","metadata":{"id":"UGCMc2Ppd-rR","colab_type":"code","colab":{}},"source":["import torchvision\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_IC8olie21GE","colab_type":"text"},"source":["#### 1. Mobilenet_v2"]},{"cell_type":"code","metadata":{"id":"cukXGxWk1WtO","colab_type":"code","outputId":"1c2db8fe-1068-4235-9348-d70fcb3ea02b","executionInfo":{"status":"error","timestamp":1587575181204,"user_tz":240,"elapsed":934,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n","backbone.out_channels = 1280\n","anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n","                                    aspect_ratios=((0.5, 1.0, 2.0),))\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","                                                output_size=7,\n","                                                sampling_ratio=2)\n","model = torchvision.models.detection.faster_rcnn.FasterRCNN(backbone,\n","                    num_classes=21,\n","                    rpn_anchor_generator=anchor_generator,\n","                    box_roi_pool=roi_pooler)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-47b1e48fc071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n\u001b[1;32m      4\u001b[0m                                     aspect_ratios=((0.5, 1.0, 2.0),))\n\u001b[1;32m      5\u001b[0m roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"]}]},{"cell_type":"code","metadata":{"id":"jVBYaALa2xOK","colab_type":"code","colab":{}},"source":["model.eval()\n","x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n","predictions = model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7XYTwLa26Mk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmOGwmnO26uZ","colab_type":"text"},"source":["#### 2. CustomVGG16"]},{"cell_type":"code","metadata":{"id":"xqIB1q2yd-rl","colab_type":"code","colab":{}},"source":["def customize_VGG16():\n","    model = torchvision.models.vgg16(pretrained=True)\n","    \n","    features = list(model.features)[:30]\n","    classifier = model.classifier\n","    \n","    classifier = list(classifier)\n","    # delete the Linear layer\n","    del classifier[6]\n","    classifier = nn.Sequential(*classifier)\n","\n","    #freeze top4 conv layer\n","    for layer in features[:10]:\n","        for p in layer.parameters():\n","            p.requires_grad = False\n","    features = nn.Sequential(*features)\n","        \n","    return features, classifier\n","backbone, box_head = customize_VGG16()\n","backbone.out_channels = 512\n","anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n","                                           aspect_ratios=((0.5, 1.0, 2.0),))\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","                                                output_size=7,\n","                                                sampling_ratio=2)\n"],"execution_count":0,"outputs":[]}]}