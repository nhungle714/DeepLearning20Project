{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"objectDectionFastRCNN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d976eaba52b14826a08be77806716d55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e8b3bddac3a340148ff50ba131e07f72","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_81d865a923a24650be500c823da350e6","IPY_MODEL_8e8204efdde4444c9bd6b9fd195a5287"]}},"e8b3bddac3a340148ff50ba131e07f72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81d865a923a24650be500c823da350e6":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_df4c4eca7ab8427fb66a258f9b69d670","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":167502836,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":167502836,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee12afe586f74133aee8e354af1e239c"}},"8e8204efdde4444c9bd6b9fd195a5287":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_03f72777ea534c218cb8be8e6a8cb477","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 160M/160M [01:16&lt;00:00, 2.19MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3043631df8a48ca93dca05b923be2f6"}},"df4c4eca7ab8427fb66a258f9b69d670":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ee12afe586f74133aee8e354af1e239c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03f72777ea534c218cb8be8e6a8cb477":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e3043631df8a48ca93dca05b923be2f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LMpEF8ZDd-lt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"3a10511e-b657-42f4-a288-7459399306c2","executionInfo":{"status":"ok","timestamp":1587653021395,"user_tz":240,"elapsed":23589,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6qAWv9YOfRAi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":155},"outputId":"f722d12e-67fe-43ab-e0af-6dadd9d2a3c5","executionInfo":{"status":"ok","timestamp":1587653056609,"user_tz":240,"elapsed":2608,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["import os\n","!ls \n","os.chdir('gdrive/My Drive/dl20/final_project/FinalProject')\n","\n","!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["gdrive\tsample_data\n","'=1.4'\t\t  env\t\t\t     objectDectionFastRCNN.ipynb\n","'=2.0.8'\t  explore_the_data.ipynb     __pycache__\n"," coco_eval.py\t  group_by_aspect_ratio.py   README.md\n"," coco_utils.py\t  helper.py\t\t     requirements.txt\n"," data\t\t  Mask_RCNN\t\t     train.py\n"," data_helper.py   MaskRCNN.ipynb\t     transforms.py\n"," engine.py\t  model_loader.py\t     utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X9PMrKKreF3N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"95c4a200-1b03-4b39-cb97-de77816f6c44","executionInfo":{"status":"ok","timestamp":1587653062423,"user_tz":240,"elapsed":4310,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["import os\n","from PIL import Image\n","\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","matplotlib.rcParams['figure.figsize'] = [5, 5]\n","matplotlib.rcParams['figure.dpi'] = 200\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","from data_helper import *\n","from helper import collate_fn, draw_box\n","\n","import pickle\n","import time\n","import copy"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"23wjtm3ufX2t","colab_type":"text"},"source":["# Test an example code"]},{"cell_type":"code","metadata":{"id":"Z-mow3YMfT-_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["d976eaba52b14826a08be77806716d55","e8b3bddac3a340148ff50ba131e07f72","81d865a923a24650be500c823da350e6","8e8204efdde4444c9bd6b9fd195a5287","df4c4eca7ab8427fb66a258f9b69d670","ee12afe586f74133aee8e354af1e239c","03f72777ea534c218cb8be8e6a8cb477","e3043631df8a48ca93dca05b923be2f6"]},"outputId":"86d3d876-7f7e-4968-8d21-a82f2d6da56f","executionInfo":{"status":"ok","timestamp":1587653086288,"user_tz":240,"elapsed":25411,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)\n","labels = torch.randint(1, 91, (4, 11))\n","images = list(image for image in images)\n","targets = []\n","for i in range(len(images)):\n","    d = {}\n","    d['boxes'] = boxes[i]\n","    d['labels'] = labels[i]\n","    targets.append(d)\n","output = model(images, targets)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d976eaba52b14826a08be77806716d55","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=167502836), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iQ7-Fn_eg_f_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"f4d7b6c4-2b71-44af-ad75-e55d1ed9d64d","executionInfo":{"status":"ok","timestamp":1587653086289,"user_tz":240,"elapsed":19505,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["output"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'loss_box_reg': tensor(0.0049, grad_fn=<DivBackward0>),\n"," 'loss_classifier': tensor(0.1286, grad_fn=<NllLossBackward>),\n"," 'loss_objectness': tensor(13.9017, grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n"," 'loss_rpn_box_reg': tensor(nan, grad_fn=<DivBackward0>)}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"A16_Anied-mJ","colab_type":"code","colab":{}},"source":["# All the images are saved in image_folder\n","# All the labels are saved in the annotation_csv file\n","\n","# image_folder = '../data'\n","# annotation_csv = '../data/annotation.csv'\n","\n","image_folder = 'data'\n","annotation_csv = 'data/annotation.csv'\n","labeled_scene_index = np.arange(133, 134)\n","\n","# image_folder = '/Users/nhungle/Downloads/dl20_data'\n","# annotation_csv = '/Users/nhungle/Downloads/dl20_data/annotation.csv'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tVqN7YCd-nQ","colab_type":"code","colab":{}},"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if cuda else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n-PzB4lPd-n7","colab_type":"text"},"source":["# Labeled dataset"]},{"cell_type":"code","metadata":{"id":"Mk75N39Cd-n8","colab_type":"code","colab":{}},"source":["def inspect_target(index):\n","    NUM_SAMPLE_PER_SCENE = 126\n","    NUM_IMAGE_PER_SAMPLE = 6\n","    image_names = [\n","        'CAM_FRONT_LEFT.jpeg',\n","        'CAM_FRONT.jpeg',\n","        'CAM_FRONT_RIGHT.jpeg',\n","        'CAM_BACK_LEFT.jpeg',\n","        'CAM_BACK.jpeg',\n","        'CAM_BACK_RIGHT.jpeg',\n","        ]\n","    scene_index = labeled_scene_index \n","    scene_id = scene_index[index // NUM_SAMPLE_PER_SCENE]\n","    sample_id = index % NUM_SAMPLE_PER_SCENE\n","    sample_path = os.path.join(image_folder, f'scene_{scene_id}', f'sample_{sample_id}') \n","    images = []\n","    for image_name in image_names:\n","        image_path = os.path.join(sample_path, image_name)\n","        image = Image.open(image_path)\n","        images.append(transform(image))\n","    image_tensor = torch.stack(images)\n","    annotation_file = annotation_csv \n","    annotation_dataframe = pd.read_csv(annotation_file)\n","    data_entries = annotation_dataframe[(annotation_dataframe['scene'] == scene_id) & (annotation_dataframe['sample'] == sample_id)]\n","    corners = data_entries[['fl_x', 'fr_x', 'bl_x', 'br_x', 'fl_y', 'fr_y','bl_y', 'br_y']].to_numpy()\n","    categories = data_entries.category_id.to_numpy()\n","    num_objects = len(categories)\n","    boxes = []\n","    for i in range(num_objects):\n","        xmin = min(corners[i][:4])\n","        xmax = max(corners[i][:4])\n","        ymin = min(corners[i][4:])\n","        ymax = max(corners[i][4:])\n","        boxes.append([xmin, ymin, xmax, ymax])\n","    return data_entries, image_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fom2g6MJd-oP","colab_type":"code","colab":{}},"source":["# The labeled dataset can only be retrieved by sample.\n","# And all the returned data are tuple of tensors, since bounding boxes may have different size\n","# You can choose whether the loader returns the extra_info. It is optional. You don't have to use it.\n","transform = torchvision.transforms.ToTensor()\n","labeled_trainset = LabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","fasterRCNN_trainset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","train_loader = torch.utils.data.DataLoader(fasterRCNN_trainset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HFKc2hcbN3e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0af1b5b0-05ea-4822-a615-2e56c73c9a54","executionInfo":{"status":"ok","timestamp":1587649500820,"user_tz":240,"elapsed":726,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["train_loader.__len__()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["126"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"-I7CPU6Gd-oi","colab_type":"code","colab":{}},"source":["sample, targets = iter(train_loader).next()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iQADn5EVgAKg","colab_type":"code","colab":{}},"source":["#targets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pgjt4k2VRU0n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"88a456da-f74c-4b6c-ed08-41f76671bf51","executionInfo":{"status":"ok","timestamp":1587653114243,"user_tz":240,"elapsed":7329,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["sample[0].shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([6, 3, 256, 306])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"XxJdONjld-oy","colab_type":"code","outputId":"f6367e4c-3d70-4a86-a9cb-cd92b32e20e8","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1587653114431,"user_tz":240,"elapsed":6806,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["index = targets[0]['image_id'].item()\n","data_entries, idx_tensor = inspect_target(index)\n","data_entries[\"category_id\"].values == targets[0]['labels'].data.numpy()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True,  True,  True,  True])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"pq87_1TsZdxH","colab_type":"text"},"source":["## Prepare inputs for the model"]},{"cell_type":"code","metadata":{"id":"C3v00HG3ZdJP","colab_type":"code","colab":{}},"source":["def extract_features(one_sample):\n","    feature_extractor = torchvision.models.resnet18(pretrained=False)\n","    feature_extractor = nn.Sequential(*list(feature_extractor.children())[:-2])\n","    #feature_extractor.to(device)\n","    # for param in feature_extractor.parameters():\n","    #     param.requires_grad = True\n","    return feature_extractor(one_sample)\n","\n","\n","def concat_features(features, dim = 2):\n","    #dim 0 ==> stacking the images in the channel dimension\n","    #dim 1 ==> stacking the images in row dimension\n","    #dim 2 ==> stacking the images in column dimension\n","    tensor_tuples = torch.unbind(features, dim=0)\n","    concatenated_fm = torch.cat(tensor_tuples, dim=dim)\n","    return concatenated_fm \n","\n","def prepare_inputs(sample):\n","    \"\"\"\n","    Input: samples is a cuda tensor with size [batch_size, 6, 3, 256, 306]\n","    Output: a list of batch_size tensor, each tensor with size [512, 16, 114]\n","    \"\"\"\n","    batchsize = sample.shape[0]\n","    fe_batch = []\n","    for i in range(batchsize):\n","        image_tensor = sample[i]\n","        features = extract_features(image_tensor)\n","        #print(features.shape)\n","        features = concat_features(features)\n","        features = features.view(3, 512, 160)\n","        #print(features.shape)\n","        fe_batch.append(features)\n","    \n","    return fe_batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuAHlunjZlLB","colab_type":"code","colab":{}},"source":["sample = torch.stack(sample)\n","images = prepare_inputs(sample)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_RhualMZrmB","colab_type":"code","colab":{}},"source":["images = list(image.to(device) for image in images)\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrbXoiO4RGse","colab_type":"text"},"source":["## Test pretrained model on my input"]},{"cell_type":"code","metadata":{"id":"LRNs29FNRGB_","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r551MU-nd-qk","colab_type":"code","colab":{}},"source":["output1 = model(images, targets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0Hxh3tYazHV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"aca552aa-3a2d-4202-9e0e-9cb7a61fd0c9","executionInfo":{"status":"ok","timestamp":1587653233103,"user_tz":240,"elapsed":922,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["output1"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'loss_box_reg': tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>),\n"," 'loss_classifier': tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward>),\n"," 'loss_objectness': tensor(1.8566, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n"," 'loss_rpn_box_reg': tensor(0.6337, device='cuda:0', grad_fn=<DivBackward0>)}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"eY5lf6lfbZTU","colab_type":"text"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"k2p5G8s6cRBv","colab_type":"code","colab":{}},"source":["# Refer to: https://github.com/pytorch/vision/blob/master/references/detection/engine.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RCAioWzd_RC","colab_type":"code","colab":{}},"source":["train_labeled_scene_index = np.arange(133, 134)\n","test_labeled_scene_index = np.arange(132, 133)\n","fasterRCNN_trainset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=train_labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","train_loader = torch.utils.data.DataLoader(fasterRCNN_trainset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)\n","fasterRCNN_testset = FastRCNNLabeledDataset(image_folder=image_folder,\n","                                  annotation_file=annotation_csv,\n","                                  scene_index=test_labeled_scene_index,\n","                                  transform=transform,\n","                                  extra_info=True\n","                                 )\n","test_loader = torch.utils.data.DataLoader(fasterRCNN_testset,\n","                                          batch_size=1,\n","                                          shuffle=True,\n","                                          num_workers=2, collate_fn=collate_fn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEsCSbEEdsgC","colab_type":"code","colab":{}},"source":["import math\n","import sys\n","import time\n","import torch\n","\n","from coco_utils import get_coco_api_from_dataset\n","from coco_eval import CocoEvaluator\n","import utils\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0mfqyfzbYgy","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                            momentum=0.9, weight_decay=0.0005)\n","# and a learning rate scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                step_size=3,\n","                                                gamma=0.1)\n","\n","# let's train it for 10 epochs\n","num_epochs = 1\n","epoch = 0\n","print_freq = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7REJR4wZiZEv","colab_type":"code","colab":{}},"source":["def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n","    model.train()\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n","    header = 'Epoch: [{}]'.format(epoch)\n","\n","    lr_scheduler = None\n","    if epoch == 0:\n","        warmup_factor = 1. / 1000\n","        warmup_iters = min(1000, len(data_loader) - 1)\n","\n","        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n","\n","    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n","        images = torch.stack(images)\n","        #print(images.shape)\n","        images = prepare_inputs(images)\n","        #print(images[0].shape)\n","\n","        images = list(image.to(device) for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        #print(loss_dict)\n","\n","        losses = sum(loss for loss in loss_dict.values())\n","        #print(losses)\n","\n","        # reduce losses over all GPUs for logging purposes\n","        loss_dict_reduced = utils.reduce_dict(loss_dict)\n","        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n","\n","        loss_value = losses_reduced.item()\n","\n","        if not math.isfinite(loss_value):\n","            print(\"Loss is {}, stopping training\".format(loss_value))\n","            print(loss_dict_reduced)\n","            sys.exit(1)\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","\n","        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n","\n","    return loss_value"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNgNdjDyimY4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"outputId":"444dc2bc-7f90-4c75-ff54-bb9e20a1d853","executionInfo":{"status":"ok","timestamp":1587653732284,"user_tz":240,"elapsed":256261,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch: [0]  [  0/126]  eta: 0:16:09  lr: 0.000045  loss: 3.5067 (3.5067)  loss_classifier: 0.1825 (0.1825)  loss_box_reg: 0.0031 (0.0031)  loss_objectness: 2.2249 (2.2249)  loss_rpn_box_reg: 1.0963 (1.0963)  time: 7.6930  data: 5.4780  max mem: 2438\n","Epoch: [0]  [ 20/126]  eta: 0:04:11  lr: 0.000844  loss: 1.5302 (1.7125)  loss_classifier: 0.1288 (0.1735)  loss_box_reg: 0.0069 (0.0110)  loss_objectness: 0.4034 (0.7001)  loss_rpn_box_reg: 0.7716 (0.8280)  time: 2.1085  data: 0.1802  max mem: 2704\n","Epoch: [0]  [ 40/126]  eta: 0:03:05  lr: 0.001643  loss: 1.0577 (1.4125)  loss_classifier: 0.1129 (0.1459)  loss_box_reg: 0.0035 (0.0089)  loss_objectness: 0.2668 (0.5234)  loss_rpn_box_reg: 0.6072 (0.7344)  time: 1.9317  data: 0.0042  max mem: 2704\n","Epoch: [0]  [ 60/126]  eta: 0:02:17  lr: 0.002443  loss: 0.8366 (1.2275)  loss_classifier: 0.1055 (0.1352)  loss_box_reg: 0.0092 (0.0105)  loss_objectness: 0.1393 (0.3985)  loss_rpn_box_reg: 0.5202 (0.6833)  time: 1.9213  data: 0.0039  max mem: 2704\n","Epoch: [0]  [ 80/126]  eta: 0:01:33  lr: 0.003242  loss: 0.6872 (1.0948)  loss_classifier: 0.1193 (0.1306)  loss_box_reg: 0.0187 (0.0121)  loss_objectness: 0.1061 (0.3268)  loss_rpn_box_reg: 0.4411 (0.6254)  time: 1.9169  data: 0.0038  max mem: 2704\n","Epoch: [0]  [100/126]  eta: 0:00:53  lr: 0.004041  loss: 0.6774 (1.0119)  loss_classifier: 0.1079 (0.1295)  loss_box_reg: 0.0189 (0.0136)  loss_objectness: 0.0657 (0.2765)  loss_rpn_box_reg: 0.4466 (0.5922)  time: 2.0496  data: 0.1210  max mem: 2704\n","Epoch: [0]  [120/126]  eta: 0:00:12  lr: 0.004840  loss: 0.5424 (0.9389)  loss_classifier: 0.1315 (0.1316)  loss_box_reg: 0.0284 (0.0166)  loss_objectness: 0.0330 (0.2378)  loss_rpn_box_reg: 0.3169 (0.5528)  time: 1.9985  data: 0.0774  max mem: 2704\n","Epoch: [0]  [125/126]  eta: 0:00:02  lr: 0.005000  loss: 0.5264 (0.9286)  loss_classifier: 0.1315 (0.1322)  loss_box_reg: 0.0363 (0.0171)  loss_objectness: 0.0413 (0.2311)  loss_rpn_box_reg: 0.3169 (0.5481)  time: 1.9931  data: 0.0775  max mem: 2704\n","Epoch: [0] Total time: 0:04:15 (2.0307 s / it)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<utils.MetricLogger at 0x7f0ac0341e48>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"bKLzAqS5jayO","colab_type":"text"},"source":["## Evaluate"]},{"cell_type":"code","metadata":{"id":"IlTgoB_LngJq","colab_type":"code","colab":{}},"source":["#model.state_dict()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QUM8FCMp9FY","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6N7S-1srTbRg","colab_type":"code","colab":{}},"source":["def prepare_pred_results(predictions):\n","    pred_boxes = []\n","    pred_labels = []\n","    pred_scores = []\n","    for prediction in predictions:\n","        #print(prediction)\n","        if len(prediction) == 0:\n","            continue\n","        boxes = prediction[\"boxes\"]\n","        boxes = reorder_coord(boxes).tolist()\n","        scores = prediction[\"scores\"].tolist()\n","        labels = prediction[\"labels\"].tolist()\n","\n","        pred_boxes.append(boxes)\n","        pred_labels.append(labels)\n","        pred_scores.append(scores)\n","\n","    return pred_boxes, pred_labels, pred_scores\n","\n","def reorder_coord(boxes):\n","    xmin, ymin, xmax, ymax = boxes.unbind(1)\n","    return torch.stack((ymin, xmin, ymax, xmax), dim=1)\n","\n","def prepare_gt(targets):\n","    gt_boxes = []\n","    gt_labels = []\n","    for target in targets:\n","        boxes = target['boxes']\n","        boxes = reorder_coord(boxes).tolist()\n","        labels = target[\"labels\"].tolist()\n","        gt_boxes.append(boxes)\n","        gt_labels.append(labels)\n","    return gt_boxes, gt_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2a_EldORlxqm","colab_type":"code","colab":{}},"source":["# Make sure that bbox_a, bbox_b = np.array\n","\n","def bbox_iou(bbox_a, bbox_b):\n","    #print(type(bbox_a), type(bbox_b))\n","    if type(bbox_a) == list or type(bbox_b) == list:\n","        bbox_a = np.array(bbox_a)\n","        bbox_b = np.array(bbox_b)\n","    #print(type(bbox_a), type(bbox_b))\n","    if bbox_a.shape[1] != 4 or bbox_b.shape[1] != 4:\n","        raise IndexError\n","\n","    # top left (i.e., ymin, xmin)\n","    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n","    # bottom right (i.e., ymax, xmax)\n","    br = np.minimum(bbox_a[:, None, 2:], bbox_b[:, 2:])\n","\n","    # Area of intersection: (tl < br) = bool, (br-tl) = (ymax-ymin) \n","    area_i = np.prod(br - tl, axis=2) * (tl < br).all(axis=2)\n","    area_a = np.prod(bbox_a[:, 2:] - bbox_a[:, :2], axis=1)\n","    area_b = np.prod(bbox_b[:, 2:] - bbox_b[:, :2], axis=1)\n","\n","    return area_i / (area_a[:, None] + area_b - area_i)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahoOrX-8ZFzT","colab_type":"code","colab":{}},"source":["def cal_TP_FP_iou(pred_bbox_c, gt_bbox_c, iou_thres):\n","    iou_table = bbox_iou(pred_bbox_c, gt_bbox_c)\n","    num_pred_bboxes = iou_table.shape[0]\n","    num_gt_bboxes = iou_table.shape[1]\n","    TP = np.zeros(num_pred_bboxes)\n","    FP = np.zeros(num_pred_bboxes)\n","    # For each pred_bounding box:\n","      # Find the most relevant gt_bbox (i.e., the gt_bbox with max IoU)\n","      # If IoU < threshold, then flag it as FP\n","      # If IoU >= threshold, then:\n","        # If that gt_bbox already has already matched with another pred_bbox:\n","          # Flag it as FP\n","        # Else:\n","          # Flag it as TP\n","\n","    # TP only happens if the pred_bbox mathes with a gt_bbox\n","    for i in range(num_pred_bboxes):\n","        gt_bbox_index = np.argmax(iou_table[i])\n","        best_pred_bbox_index_for_selected_gt_bbox = np.argmax(iou_table[:,gt_bbox_index])\n","        if iou_table[i, gt_bbox_index] > iou_thres \\\n","            and gt_bbox_index == best_pred_bbox_index_for_selected_gt_bbox:\n","            TP[i] = 1\n","        else:\n","            FP[i] = 1\n","\n","    TP_cum = np.sum(TP)\n","    FP_cum = np.sum(FP)\n","\n","    return TP_cum, FP_cum"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"honU3_7QQLwr","colab_type":"code","colab":{}},"source":["def evaluate_one_batch(predictions, test_targets, iou_thres=0.5, res=res):\n","\n","    pred_bboxes, pred_labels, pred_scores = prepare_pred_results(predictions)\n","    gt_bboxes, gt_labels = prepare_gt(test_targets)\n","    # res stores the TP_FP dict for each class\n","    # Each TP_FP dict stores the TP_FP for each class \n","    \n","    batch_total_TP = 0\n","    batch_total_FP = 0\n","    batch_total_FN = 0\n","    j = 0\n","    for pred_bbox, pred_label, pred_score, gt_bbox, gt_label in \\\n","    zip(pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels):\n","\n","        pred_bbox = np.array(pred_bbox)\n","        pred_score = np.array(pred_score)\n","        pred_label = np.array(pred_label)\n","        gt_bbox = np.array(gt_bbox)\n","        gt_label = np.array(gt_label)\n","        unique_share_classes = (np.unique(np.concatenate((pred_label, gt_label))))\n","        #print(unique_share_classes)\n","        \n","        for c in unique_share_classes:\n","            # Get all the predicted bounding boxes of class c\n","\n","            pred_class_c_index = np.where(pred_label == c)[0]\n","            pred_bbox_c = pred_bbox[pred_class_c_index]\n","            gt_class_c_index = np.where(gt_label == c)[0]\n","            #print(gt_class_c_index)\n","            gt_bbox_c = gt_bbox[gt_class_c_index]\n","            num_gt_boxes = len(gt_class_c_index)\n","            num_pred_bboxes = len(pred_class_c_index)\n","            # print('class {}'.format(c))\n","            # print('num predicted bbox for this class {}'.format(num_pred_bboxes))\n","            # print('num gt bbox for this class {}'.format(len(gt_class_c_index)))\n","\n","            if len(pred_class_c_index) == 0:\n","                class_TP = 0\n","                class_FP = 0\n","                class_FN = num_gt_boxes\n","            elif len(gt_class_c_index) == 0:\n","                class_TP = 0\n","                class_FP = num_pred_bboxes\n","                class_FN = 0\n","            else:\n","                class_TP, class_FP = cal_TP_FP_iou(pred_bbox_c, gt_bbox_c, iou_thres)\n","                class_FN = num_gt_boxes - class_TP\n","\n","            #     iou_table = bbox_iou(pred_bbox_c, gt_bbox_c)\n","            #     num_pred_bboxes = iou_table.shape[0]\n","            #     num_gt_bboxes = iou_table.shape[1]\n","            #     TP = np.zeros(len(pred_class_c_index))\n","            #     FP = np.zeros(len(pred_class_c_index))\n","            #     class_TP = 0\n","            #     class_FP = 0\n","            #     # For each pred_bounding box:\n","            #       # Find the most relevant gt_bbox (i.e., the gt_bbox with max IoU)\n","            #       # If IoU < threshold, then flag it as FP\n","            #       # If IoU >= threshold, then:\n","            #         # If that gt_bbox already has already matched with another pred_bbox:\n","            #           # Flag it as FP\n","            #         # Else:\n","            #           # Flag it as TP\n","\n","            #     # TP only happens if the pred_bbox mathes with a gt_bbox\n","\n","            # for i in range(len(pred_class_c_index)):\n","            #     gt_bbox_index = np.argmax(iou_table[i])\n","            #     best_pred_bbox_index_for_selected_gt_bbox = np.argmax(iou_table[:,gt_bbox_index])\n","            #     if iou_table[i, gt_bbox_index] > iou_thres \\\n","            #         and gt_bbox_index == best_pred_bbox_index_for_selected_gt_bbox:\n","            #         TP[i] = 1\n","            #     else:\n","            #         FP[i] = 1\n","\n","            # TP_cum = np.sum(TP)\n","            # FP_cum = np.sum(FP)\n","            # FN_cum = npos - TP_cum\n","\n","            batch_total_TP += class_TP\n","            batch_total_FP += class_FP\n","            batch_total_FN += class_FN\n","            #print(c)\n","\n","            res[c]['TP'] += class_TP\n","            res[c]['FP'] += class_FP\n","            res[c]['FN'] += class_FN\n","            \n","    return res, batch_total_TP, batch_total_FP, batch_total_FN"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nji9KKjySsLT","colab_type":"code","colab":{}},"source":["test_images, test_targets = next(iter(test_loader))\n","test_images = torch.stack(test_images)\n","#print(test_images.shape)\n","test_images = prepare_inputs(test_images)\n","#print(test_images[0].shape)\n","\n","test_images = list(image.to(device) for image in test_images)\n","test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","model.eval()\n","predictions = model(test_images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfzs9R0nS5Wr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"509ad4a6-b25c-4e17-af4a-e4e3c1ae272e","executionInfo":{"status":"ok","timestamp":1587668808512,"user_tz":240,"elapsed":738,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["res, batch_total_TP, batch_total_FP, batch_total_FN = evaluate_one_batch(predictions, test_targets, iou_thres=0.5)"],"execution_count":293,"outputs":[{"output_type":"stream","text":["class 0.0\n","num predicted bbox for this class 0\n","num gt bbox for this class 2\n","class 2.0\n","num predicted bbox for this class 0\n","num gt bbox for this class 15\n","class 3.0\n","num predicted bbox for this class 0\n","num gt bbox for this class 3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Hf3Cii6S5gf","colab_type":"code","colab":{}},"source":["def evaluate_one_epoch(test_loader, iou_thres=0.5):\n","    # Evaluate. for all data point in the evaluaton set\n","    final_res = {c: {'TP':0, 'FP': 0, 'FN': 0} for c in range(9)}\n","    final_TP = 0\n","    final_FP = 0\n","    final_FN = 0\n","\n","    for iter_, (test_images, test_targets) in enumerate(test_loader):\n","        if iter_ % 25 == 0:\n","            print('iter', iter_)\n","        test_images = torch.stack(test_images)\n","        #print(test_images.shape)\n","        test_images = prepare_inputs(test_images)\n","        #print(test_images[0].shape)\n","\n","        test_images = list(image.to(device) for image in test_images)\n","        test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","        model.eval()\n","        predictions = model(test_images)\n","\n","        # Evaluate for one batch\n","        final_res, batch_total_TP, batch_total_FP, batch_total_FN = evaluate_one_batch(predictions, \n","                                                                                test_targets,\n","                                                                                iou_thres,\n","                                                                                final_res)\n","        \n","        final_TP += batch_total_TP\n","        final_FP += batch_total_FP\n","        final_FN += batch_total_FN\n","\n","    return final_res, final_TP, final_FP, final_FN"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zop8Z75IS5ep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"0385f7fb-cb84-4221-9379-fbb4c231e520","executionInfo":{"status":"ok","timestamp":1587669068990,"user_tz":240,"elapsed":378,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["final_res"],"execution_count":302,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: {'FN': 158, 'FP': 0, 'TP': 0},\n"," 1: {'FN': 0, 'FP': 0, 'TP': 0},\n"," 2: {'FN': 3074.0, 'FP': 582.0, 'TP': 0.0},\n"," 3: {'FN': 390, 'FP': 0, 'TP': 0},\n"," 4: {'FN': 27, 'FP': 0, 'TP': 0},\n"," 5: {'FN': 0, 'FP': 0, 'TP': 0},\n"," 6: {'FN': 20, 'FP': 0, 'TP': 0},\n"," 7: {'FN': 0, 'FP': 0, 'TP': 0},\n"," 8: {'FN': 0, 'FP': 0, 'TP': 0}}"]},"metadata":{"tags":[]},"execution_count":302}]},{"cell_type":"code","metadata":{"id":"JFT09TgzS5cW","colab_type":"code","colab":{}},"source":["def evaluate_threst_score(TP, FP, FN):\n","    return (TP / (TP + FP + FN))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEx2ls44dlXz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"5efd5c32-b10c-4f6a-c74c-01bc3da69de1","executionInfo":{"status":"ok","timestamp":1587669279458,"user_tz":240,"elapsed":329,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["evaluate_threst_score(final_TP, final_FP, final_FN)"],"execution_count":304,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":304}]},{"cell_type":"markdown","metadata":{"id":"ve5Zlqi-dvxf","colab_type":"text"},"source":["## Train and Evaluate for Multiple Epochs"]},{"cell_type":"code","metadata":{"id":"mm_4-JrdeH59","colab_type":"code","colab":{}},"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                            momentum=0.9, weight_decay=0.0005)\n","# and a learning rate scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                step_size=3,\n","                                                gamma=0.1)\n","\n","# let's train it for 10 epochs\n","num_epochs = 2\n","epoch = 0\n","print_freq = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxJ2JfOufhEI","colab_type":"code","colab":{}},"source":["train_losses = []\n","eval_threatscores = []\n","eval_final_res = []\n","best_eval_ts = 0\n","\n","best_model_wts = copy.deepcopy(model.state_dict())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4fAgXgidudg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"d83a0b5e-cd8e-428c-9132-77b80d73d5be"},"source":["\n","for epoch in range(num_epochs):\n","    loss = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq)\n","    train_losses.append(loss)\n","    final_res, final_TP, final_FP, final_FN = evaluate_one_epoch(test_loader, iou_thres=0.5)\n","    eval_final_res.append(final_res)\n","    eval_ts = evaluate_threst_score(final_TP, final_FP, final_FN)\n","    eval_threatscores.append(eval_ts)\n","\n","    if eval_ts > best_eval_ts:\n","        best_eval_ts = eval_ts \n","        best_model_wts = copy.deepcopy(model.state_dict())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: [0]  [  0/126]  eta: 0:05:46  lr: 0.000045  loss: 2.2160 (2.2160)  loss_classifier: 0.0793 (0.0793)  loss_box_reg: 0.0013 (0.0013)  loss_objectness: 1.5412 (1.5412)  loss_rpn_box_reg: 0.5941 (0.5941)  time: 2.7531  data: 0.2919  max mem: 4601\n","Epoch: [0]  [ 20/126]  eta: 0:03:29  lr: 0.000844  loss: 1.6727 (1.7804)  loss_classifier: 0.1849 (0.1818)  loss_box_reg: 0.0065 (0.0092)  loss_objectness: 0.5938 (0.7468)  loss_rpn_box_reg: 0.8371 (0.8426)  time: 1.9382  data: 0.0041  max mem: 4868\n","Epoch: [0]  [ 40/126]  eta: 0:02:47  lr: 0.001643  loss: 0.9420 (1.4098)  loss_classifier: 0.1128 (0.1483)  loss_box_reg: 0.0100 (0.0094)  loss_objectness: 0.3056 (0.5333)  loss_rpn_box_reg: 0.5741 (0.7188)  time: 1.9286  data: 0.0040  max mem: 4868\n","Epoch: [0]  [ 60/126]  eta: 0:02:08  lr: 0.002443  loss: 0.7218 (1.2052)  loss_classifier: 0.0959 (0.1333)  loss_box_reg: 0.0152 (0.0116)  loss_objectness: 0.1594 (0.4293)  loss_rpn_box_reg: 0.4378 (0.6311)  time: 1.9368  data: 0.0042  max mem: 4868\n","Epoch: [0]  [ 80/126]  eta: 0:01:29  lr: 0.003242  loss: 0.7236 (1.0853)  loss_classifier: 0.1227 (0.1327)  loss_box_reg: 0.0161 (0.0137)  loss_objectness: 0.0800 (0.3444)  loss_rpn_box_reg: 0.4700 (0.5945)  time: 1.9270  data: 0.0041  max mem: 4868\n","Epoch: [0]  [100/126]  eta: 0:00:50  lr: 0.004041  loss: 0.6513 (1.0092)  loss_classifier: 0.1049 (0.1282)  loss_box_reg: 0.0104 (0.0138)  loss_objectness: 0.0728 (0.2940)  loss_rpn_box_reg: 0.4377 (0.5732)  time: 1.9331  data: 0.0044  max mem: 4868\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OsAuhVThduhA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXmfiNDgJRY-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"aaeffc31-aa15-44d0-9d0a-61b203f837f1","executionInfo":{"status":"ok","timestamp":1587666212852,"user_tz":240,"elapsed":351,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["# res stores the TP_FP dict for each sample in the batch\n","# Each TP_FP dict stores the TP_FP for each class \n","res = []\n","batch_total_TP = 0\n","batch_total_FP = 0\n","batch_total_FN = 0\n","j = 0\n","for pred_bbox, pred_label, pred_score, gt_bbox, gt_label in \\\n","zip(pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels):\n","\n","    pred_bbox = np.array(pred_bbox)\n","    pred_score = np.array(pred_score)\n","    pred_label = np.array(pred_label)\n","    gt_bbox = np.array(gt_bbox)\n","    gt_label = np.array(gt_label)\n","    unique_share_classes = (np.unique(np.concatenate((pred_label, gt_label))))\n","    #print(unique_share_classes)\n","    TP_FP_class = {}\n","    for c in unique_share_classes:\n","        # Get all the predicted bounding boxes of class c\n","\n","        pred_class_c_index = np.where(pred_label == c)[0]\n","        pred_bbox_c = pred_bbox[pred_class_c_index]\n","        gt_class_c_index = np.where(gt_label == c)[0]\n","        #print(gt_class_c_index)\n","        gt_bbox_c = gt_bbox[gt_class_c_index]\n","        npos = len(gt_class_c_index)\n","        print('class {}'.format(c))\n","        print('num predicted bbox for this class {}'.format(len(pred_class_c_index)))\n","        print('num gt bbox for this class {}'.format(len(gt_class_c_index)))\n","\n","        iou_table = bbox_iou(pred_bbox_c, gt_bbox_c)\n","        num_pred_bboxes = iou_table.shape[0]\n","        num_gt_bboxes = iou_table.shape[1]\n","        TP = np.zeros(len(pred_class_c_index))\n","        FP = np.zeros(len(pred_class_c_index))\n","        # For each pred_bounding box:\n","          # Find the most relevant gt_bbox (i.e., the gt_bbox with max IoU)\n","          # If IoU < threshold, then flag it as FP\n","          # If IoU >= threshold, then:\n","            # If that gt_bbox already has already matched with another pred_bbox:\n","              # Flag it as FP\n","            # Else:\n","              # Flag it as TP\n","\n","        # TP only happens if the pred_bbox mathes with a gt_bbox\n","\n","        for i in range(len(pred_class_c_index)):\n","            gt_bbox_index = np.argmax(iou_table[i])\n","            best_pred_bbox_index_for_selected_gt_bbox = np.argmax(iou_table[:,gt_bbox_index])\n","            if iou_table[i, gt_bbox_index] > iou_thres \\\n","                and gt_bbox_index == best_pred_bbox_index_for_selected_gt_bbox:\n","                TP[i] = 1\n","            else:\n","                FP[i] = 1\n","        TP_cum = np.sum(TP)\n","        FP_cum = np.sum(FP)\n","        FN_cum = npos - TP_cum\n","\n","        batch_total_TP += TP_cum\n","        batch_total_FP += FP_cum\n","        batch_total_FN += FN_cum\n","        #print(c)\n","\n","        TP_FP_class[c] = [TP_cum, FP_cum, FN_cum]\n","\n","    res.append(TP_FP_class)\n"],"execution_count":248,"outputs":[{"output_type":"stream","text":["class 0\n","num predicted bbox for this class 0\n","num gt bbox for this class 1\n","class 2\n","num predicted bbox for this class 4\n","num gt bbox for this class 27\n","class 3\n","num predicted bbox for this class 0\n","num gt bbox for this class 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bZCj9OMXrg6-","colab_type":"code","colab":{}},"source":["def evaluate_test_samples(model, test_images, test_targets):\n","  test_images = torch.stack(test_images)\n","  #print(test_images.shape)\n","  test_images = prepare_inputs(test_images)\n","  #print(test_images[0].shape)\n","\n","  test_images = list(image.to(device) for image in test_images)\n","  test_targets = [{k: v.to(device) for k, v in t.items()} for t in test_targets]\n","\n","  model.eval()\n","  predictions = model(test_images)\n","\n","  for i in range(len(predictions)):\n","      num_objects_predicted = len(predictions[i]['labels'])\n","      num_objects_gt = len(test_targets[i]['labels'])\n","      print('num object predicted: {}, num_object_ground_truth: {}'.format(num_objects_predicted, num_objects_gt))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i64fm2Ddye_H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"5ccacf57-22cd-4772-c071-f0793f6a10e8","executionInfo":{"status":"ok","timestamp":1587590986107,"user_tz":240,"elapsed":24130,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["for i in range(3):\n","    test_images, test_targets = next(iter(test_loader))\n","    evaluate_test_samples(model, test_images, test_targets)"],"execution_count":97,"outputs":[{"output_type":"stream","text":["num object predicted: 58, num_object_ground_truth: 17\n","num object predicted: 38, num_object_ground_truth: 27\n","num object predicted: 28, num_object_ground_truth: 20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hXslpd4-d-rQ","colab_type":"text"},"source":["## Customize Fast RCNN"]},{"cell_type":"code","metadata":{"id":"UGCMc2Ppd-rR","colab_type":"code","colab":{}},"source":["import torchvision\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_IC8olie21GE","colab_type":"text"},"source":["#### 1. Mobilenet_v2"]},{"cell_type":"code","metadata":{"id":"cukXGxWk1WtO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"1c2db8fe-1068-4235-9348-d70fcb3ea02b","executionInfo":{"status":"error","timestamp":1587575181204,"user_tz":240,"elapsed":934,"user":{"displayName":"Nhung Hong Le","photoUrl":"","userId":"11957069750784655483"}}},"source":["backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n","backbone.out_channels = 1280\n","anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n","                                    aspect_ratios=((0.5, 1.0, 2.0),))\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","                                                output_size=7,\n","                                                sampling_ratio=2)\n","model = torchvision.models.detection.faster_rcnn.FasterRCNN(backbone,\n","                    num_classes=21,\n","                    rpn_anchor_generator=anchor_generator,\n","                    box_roi_pool=roi_pooler)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-47b1e48fc071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n\u001b[1;32m      4\u001b[0m                                     aspect_ratios=((0.5, 1.0, 2.0),))\n\u001b[1;32m      5\u001b[0m roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"]}]},{"cell_type":"code","metadata":{"id":"jVBYaALa2xOK","colab_type":"code","colab":{}},"source":["model.eval()\n","x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n","predictions = model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7XYTwLa26Mk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmOGwmnO26uZ","colab_type":"text"},"source":["#### 2. CustomVGG16"]},{"cell_type":"code","metadata":{"id":"xqIB1q2yd-rl","colab_type":"code","colab":{}},"source":["def customize_VGG16():\n","    model = torchvision.models.vgg16(pretrained=True)\n","    \n","    features = list(model.features)[:30]\n","    classifier = model.classifier\n","    \n","    classifier = list(classifier)\n","    # delete the Linear layer\n","    del classifier[6]\n","    classifier = nn.Sequential(*classifier)\n","\n","    #freeze top4 conv layer\n","    for layer in features[:10]:\n","        for p in layer.parameters():\n","            p.requires_grad = False\n","    features = nn.Sequential(*features)\n","        \n","    return features, classifier\n","backbone, box_head = customize_VGG16()\n","backbone.out_channels = 512\n","anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n","                                           aspect_ratios=((0.5, 1.0, 2.0),))\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n","                                                output_size=7,\n","                                                sampling_ratio=2)\n"],"execution_count":0,"outputs":[]}]}